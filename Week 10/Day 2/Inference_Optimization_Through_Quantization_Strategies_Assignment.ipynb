{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "njT94cGl7THo"
      ],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6800710aaa0745d38fbdde751edffa8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_e240d90cfd364a31a82d66824a17da40",
              "IPY_MODEL_d8f6172b9b6c447480adc868d3a4d931",
              "IPY_MODEL_b8e6404b9e0b4709b84a3df5fd74de82",
              "IPY_MODEL_7bd709b64ba8448db9790be04f36db98"
            ],
            "layout": "IPY_MODEL_416494edded14f7d9e00b5306ec0363e"
          }
        },
        "20536f663e534d4e9fbb1c91c441c0d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0fba47081f9242bc9af9dbca04ee8170",
            "placeholder": "​",
            "style": "IPY_MODEL_556e6b5ef1844f1681da3f8649466646",
            "value": "<center> <img\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.svg\nalt='Hugging Face'> <br> Copy a token from <a\nhref=\"https://huggingface.co/settings/tokens\" target=\"_blank\">your Hugging Face\ntokens page</a> and paste it below. <br> Immediately click login after copying\nyour token or it might be stored in plain text in this notebook file. </center>"
          }
        },
        "3dc03a0e12d24777a5b2f579e132a2e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "PasswordModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_3043d2330ede4f0896ff5b8734261f93",
            "placeholder": "​",
            "style": "IPY_MODEL_bc851ba00d3d4715b686168720251955",
            "value": ""
          }
        },
        "5e51e8c4f3e54359974c50e5d2eef111": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "CheckboxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "CheckboxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "CheckboxView",
            "description": "Add token as git credential?",
            "description_tooltip": null,
            "disabled": false,
            "indent": true,
            "layout": "IPY_MODEL_2d278d450e3c43c0a3b6d4aa8f334e00",
            "style": "IPY_MODEL_85b1f6822b5e455684cef1aed2946825",
            "value": true
          }
        },
        "dc0917cb310d42afbf0a460002a551a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_add424a7a75b4d498f3cf04a3007ad3b",
            "style": "IPY_MODEL_a28cab038ea24d9a99fa94a7b1cc209a",
            "tooltip": ""
          }
        },
        "db71c63981eb465f8dd6030e589fba35": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8bf8078d853f417eb0f4d6c430f0e42a",
            "placeholder": "​",
            "style": "IPY_MODEL_9d4210aeaea64815a824b148ef01aff0",
            "value": "\n<b>Pro Tip:</b> If you don't already have one, you can create a dedicated\n'notebooks' token with 'write' access, that you can then easily reuse for all\nnotebooks. </center>"
          }
        },
        "416494edded14f7d9e00b5306ec0363e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "0fba47081f9242bc9af9dbca04ee8170": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "556e6b5ef1844f1681da3f8649466646": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3043d2330ede4f0896ff5b8734261f93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bc851ba00d3d4715b686168720251955": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2d278d450e3c43c0a3b6d4aa8f334e00": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "85b1f6822b5e455684cef1aed2946825": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "add424a7a75b4d498f3cf04a3007ad3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a28cab038ea24d9a99fa94a7b1cc209a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "8bf8078d853f417eb0f4d6c430f0e42a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9d4210aeaea64815a824b148ef01aff0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a8838273af20416fba776c3e94775e67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_289667e0c994464abef29e5c52db6feb",
            "placeholder": "​",
            "style": "IPY_MODEL_427d559298a5488e88e65a863bacca1b",
            "value": "Connecting..."
          }
        },
        "289667e0c994464abef29e5c52db6feb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "427d559298a5488e88e65a863bacca1b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e240d90cfd364a31a82d66824a17da40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e9dcc0c281194c4f8b2d0b22c8b28b93",
            "placeholder": "​",
            "style": "IPY_MODEL_bdf8dcb8e9aa4ebcab9eebfce1ff9a71",
            "value": "Token is valid (permission: write)."
          }
        },
        "d8f6172b9b6c447480adc868d3a4d931": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f7c278091a384389886d91d0de5ffcaa",
            "placeholder": "​",
            "style": "IPY_MODEL_de092604a9d64af9a23d406c44c4351c",
            "value": "Your token has been saved in your configured git credential helpers (store)."
          }
        },
        "b8e6404b9e0b4709b84a3df5fd74de82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_808960e3ea8241289aad4af38e0fb34f",
            "placeholder": "​",
            "style": "IPY_MODEL_c5a7dc76ecd64d05bc1ccbf79e4ff840",
            "value": "Your token has been saved to /root/.cache/huggingface/token"
          }
        },
        "7bd709b64ba8448db9790be04f36db98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_82bd7c2fe81146e1bee9c20566d2f9de",
            "placeholder": "​",
            "style": "IPY_MODEL_e654cdeeb96044e78af9f34fe1ee65d4",
            "value": "Login successful"
          }
        },
        "e9dcc0c281194c4f8b2d0b22c8b28b93": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bdf8dcb8e9aa4ebcab9eebfce1ff9a71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f7c278091a384389886d91d0de5ffcaa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "de092604a9d64af9a23d406c44c4351c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "808960e3ea8241289aad4af38e0fb34f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c5a7dc76ecd64d05bc1ccbf79e4ff840": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "82bd7c2fe81146e1bee9c20566d2f9de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e654cdeeb96044e78af9f34fe1ee65d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c290bd84649a45bc9a75468c8b6b2034": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5b46368e1e174dad981f62576c7a4155",
              "IPY_MODEL_0f2b776edc304fda9b79b6223654d45c",
              "IPY_MODEL_16b711896f2142bc98c6468a3126dba2"
            ],
            "layout": "IPY_MODEL_15df3fd89de343c7af3b8cc0ce749070"
          }
        },
        "5b46368e1e174dad981f62576c7a4155": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_19c455966afb414d8c306982c2ca1dd9",
            "placeholder": "​",
            "style": "IPY_MODEL_0fca593180af45c9b85f9bc84857194e",
            "value": "Fetching 16 files: 100%"
          }
        },
        "0f2b776edc304fda9b79b6223654d45c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e88202f07b87454091798e2bfe9200c3",
            "max": 16,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_4f8ba98960454d74adfd1cf050fd7df1",
            "value": 16
          }
        },
        "16b711896f2142bc98c6468a3126dba2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ef16ee7f377747bbacdba3bd2d9ccc9e",
            "placeholder": "​",
            "style": "IPY_MODEL_fe74007752464ad6ba49ca40b88a28fb",
            "value": " 16/16 [00:00&lt;00:00, 1114.17it/s]"
          }
        },
        "15df3fd89de343c7af3b8cc0ce749070": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19c455966afb414d8c306982c2ca1dd9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0fca593180af45c9b85f9bc84857194e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e88202f07b87454091798e2bfe9200c3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4f8ba98960454d74adfd1cf050fd7df1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "ef16ee7f377747bbacdba3bd2d9ccc9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe74007752464ad6ba49ca40b88a28fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e466cf748f9241a8b185b8e802ea66de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_69c4016af38645cc9727246cdd687ca7",
              "IPY_MODEL_6bbbe12a68a74994af20b97adde05ef6",
              "IPY_MODEL_986b620e7cea4e16b86ce6eae493d9f2"
            ],
            "layout": "IPY_MODEL_8ececf52fae14597b69b668ce791bdde"
          }
        },
        "69c4016af38645cc9727246cdd687ca7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dd72f1d38f4848e08458cbb5f586c14e",
            "placeholder": "​",
            "style": "IPY_MODEL_3217a95296214972a64b02b452081da2",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "6bbbe12a68a74994af20b97adde05ef6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_dee59bb317bb44f9ad680c93f3e187df",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_aaf1884238a8435b80a5d68925de3067",
            "value": 4
          }
        },
        "986b620e7cea4e16b86ce6eae493d9f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7dd39c6ca4c9456589ee9b8846c5d6b6",
            "placeholder": "​",
            "style": "IPY_MODEL_f333543b52454c5ea0b554b428d75117",
            "value": " 4/4 [00:10&lt;00:00,  2.23s/it]"
          }
        },
        "8ececf52fae14597b69b668ce791bdde": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd72f1d38f4848e08458cbb5f586c14e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3217a95296214972a64b02b452081da2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dee59bb317bb44f9ad680c93f3e187df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aaf1884238a8435b80a5d68925de3067": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7dd39c6ca4c9456589ee9b8846c5d6b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f333543b52454c5ea0b554b428d75117": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Inference Optimization Through Quantization Strategies\n",
        "\n",
        "We'll take a look at how effective post-training quantization strategies can be when it comes to decreasing inference latency.\n",
        "\n"
      ],
      "metadata": {
        "id": "HxN9nJHz_OcP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hkDQxjvdt2Fk",
        "outputId": "52468441-2f12-4996-ac26-7a3b1601567a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.1/797.1 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -qU transformers autoawq accelerate openai huggingface-hub peft torch==2.4.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from getpass import getpass\n",
        "\n",
        "os.environ[\"HF_TOKEN\"] = getpass(\"HF_TOKEN\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z8wI7X6212sZ",
        "outputId": "37df94a9-c61e-4962-b78f-57f89b40e872"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "HF_TOKEN··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "\n",
        "notebook_login()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145,
          "referenced_widgets": [
            "6800710aaa0745d38fbdde751edffa8d",
            "20536f663e534d4e9fbb1c91c441c0d9",
            "3dc03a0e12d24777a5b2f579e132a2e0",
            "5e51e8c4f3e54359974c50e5d2eef111",
            "dc0917cb310d42afbf0a460002a551a5",
            "db71c63981eb465f8dd6030e589fba35",
            "416494edded14f7d9e00b5306ec0363e",
            "0fba47081f9242bc9af9dbca04ee8170",
            "556e6b5ef1844f1681da3f8649466646",
            "3043d2330ede4f0896ff5b8734261f93",
            "bc851ba00d3d4715b686168720251955",
            "2d278d450e3c43c0a3b6d4aa8f334e00",
            "85b1f6822b5e455684cef1aed2946825",
            "add424a7a75b4d498f3cf04a3007ad3b",
            "a28cab038ea24d9a99fa94a7b1cc209a",
            "8bf8078d853f417eb0f4d6c430f0e42a",
            "9d4210aeaea64815a824b148ef01aff0",
            "a8838273af20416fba776c3e94775e67",
            "289667e0c994464abef29e5c52db6feb",
            "427d559298a5488e88e65a863bacca1b",
            "e240d90cfd364a31a82d66824a17da40",
            "d8f6172b9b6c447480adc868d3a4d931",
            "b8e6404b9e0b4709b84a3df5fd74de82",
            "7bd709b64ba8448db9790be04f36db98",
            "e9dcc0c281194c4f8b2d0b22c8b28b93",
            "bdf8dcb8e9aa4ebcab9eebfce1ff9a71",
            "f7c278091a384389886d91d0de5ffcaa",
            "de092604a9d64af9a23d406c44c4351c",
            "808960e3ea8241289aad4af38e0fb34f",
            "c5a7dc76ecd64d05bc1ccbf79e4ff840",
            "82bd7c2fe81146e1bee9c20566d2f9de",
            "e654cdeeb96044e78af9f34fe1ee65d4"
          ]
        },
        "id": "04UryyDjJg6w",
        "outputId": "faead7dc-f23b-40d3-9db8-cd0bdf756edb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6800710aaa0745d38fbdde751edffa8d"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Simple Benchmark: `BitsAndBytes` vs. GPTQ vs. AWQ\n",
        "\n",
        "We've learned, at this point, about BitsAndBytes and how much memory footprint we can save using Tim Dettmer's libraries. However, we've always had to include a small caveat:\n",
        "\n",
        "> BitsAndBytes does not improve inference performance, in fact, there is a small inference penalty for using it.\n",
        "\n",
        "Enter: GPTQ & AWQ!\n",
        "\n",
        "By taking advantage of a number of innovative techniques, GPTQ & AWQ are able to provide inference-time benefits *without* sacrificing as much accuracy/etc. as BitsAndBytes.\n",
        "\n",
        "There is one distinct *disadvantage* to GPTQ and AWQ, which is that they are post-training Quantization strategies - and so are not useful while fine-tuning/training models.\n",
        "\n",
        "Let's take a look at the inference-time benefits by comparing three Hugging Face Inference Endpoints, each running the model in GPTQ/AWQ/BNBs respectively, to see how they perform.\n",
        "\n"
      ],
      "metadata": {
        "id": "PENXQh6w_f8W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> NOTE: The following cell will take a while to install - please move on to Activity #1 while you wait for the installation to complete."
      ],
      "metadata": {
        "id": "m0cD7-d-ZzkC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -qU gptqmodel --no-build-isolation"
      ],
      "metadata": {
        "id": "v5blRCMbZxb-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 🏗️ Activity #1:\n",
        "\n",
        "You must spin up a total of 3 inference endpoints:\n",
        "\n",
        "1. Regular [`meta-llama/Llama-3.1-8B-Instruct`](https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct) (or NousResearch variant if you don't have access to Meta's weights)\n",
        "2. [Hugging Quants\n",
        "Meta-Llama-3.1-8B-Instruct-GPTQ-INT4](https://huggingface.co/hugging-quants/Meta-Llama-3.1-8B-Instruct-GPTQ-INT4) weights.\n",
        "3. [Hugging Quants\n",
        "Meta-Llama-3.1-8B-Instruct-AWQ-INT4](https://huggingface.co/hugging-quants/Meta-Llama-3.1-8B-Instruct-AWQ-INT4) weights.\n",
        "\n",
        "> NOTE: You can spin these up all at once, or serially, depending on your preference."
      ],
      "metadata": {
        "id": "rGEpw1lrRny8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Big Wall of Test Strings\n",
        "\n",
        "~100 test strings to do some generations with."
      ],
      "metadata": {
        "id": "QcEPXuGk67q_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Wall of Strings"
      ],
      "metadata": {
        "id": "njT94cGl7THo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_sentences = [\n",
        "    \"The quick brown fox jumps over the lazy dog.\",\n",
        "    \"I can't believe I ate the whole thing.\",\n",
        "    \"To be or not to be, that is the question.\",\n",
        "    \"All you need is love.\",\n",
        "    \"Houston, we have a problem.\",\n",
        "    \"Elementary, my dear Watson.\",\n",
        "    \"Life is like a box of chocolates.\",\n",
        "    \"May the Force be with you.\",\n",
        "    \"E.T. phone home.\",\n",
        "    \"There's no place like home.\",\n",
        "    \"I'll be back.\",\n",
        "    \"Here's looking at you, kid.\",\n",
        "    \"You talkin' to me?\",\n",
        "    \"I'm going to make him an offer he can't refuse.\",\n",
        "    \"You can't handle the truth!\",\n",
        "    \"I see dead people.\",\n",
        "    \"Say hello to my little friend!\",\n",
        "    \"You had me at hello.\",\n",
        "    \"I'm the king of the world!\",\n",
        "    \"I'll have what she's having.\",\n",
        "    \"Keep your friends close, but your enemies closer.\",\n",
        "    \"I feel the need... the need for speed!\",\n",
        "    \"You're gonna need a bigger boat.\",\n",
        "    \"Nobody puts Baby in a corner.\",\n",
        "    \"I'm walking here! I'm walking here!\",\n",
        "    \"You complete me.\",\n",
        "    \"I drink your milkshake!\",\n",
        "    \"Why so serious?\",\n",
        "    \"I'm not bad. I'm just drawn that way.\",\n",
        "    \"You can't sit with us!\",\n",
        "    \"I volunteer as tribute!\",\n",
        "    \"Winter is coming.\",\n",
        "    \"I solemnly swear that I am up to no good.\",\n",
        "    \"Live long and prosper.\",\n",
        "    \"I'm the one who knocks.\",\n",
        "    \"You know nothing, Jon Snow.\",\n",
        "    \"I am Groot.\",\n",
        "    \"Not all those who wander are lost.\",\n",
        "    \"The night is dark and full of terrors.\",\n",
        "    \"A Lannister always pays his debts.\",\n",
        "    \"Bazinga!\",\n",
        "    \"How you doin'?\",\n",
        "    \"Wubba lubba dub dub!\",\n",
        "    \"I am the danger.\",\n",
        "    \"Clear eyes, full hearts, can't lose.\",\n",
        "    \"Doh!\",\n",
        "    \"Yada, yada, yada.\",\n",
        "    \"How you doin'?\",\n",
        "    \"Suit up!\",\n",
        "    \"That's what she said.\",\n",
        "    \"Pivot! Pivot! Pivot!\",\n",
        "    \"I'm not a regular mom, I'm a cool mom.\",\n",
        "    \"You're killing me, Smalls!\",\n",
        "    \"I am serious. And don't call me Shirley.\",\n",
        "    \"I love the smell of napalm in the morning.\",\n",
        "    \"I'm not arguing, I'm just explaining why I'm right.\",\n",
        "    \"I'm not bossy, I just have better ideas.\",\n",
        "    \"I'm not saying it was aliens, but it was aliens.\",\n",
        "    \"I'm not saying I'm Batman, I'm just saying no one has ever seen me and Batman in the same room together.\",\n",
        "    \"I'm not saying I'm Wonder Woman, I'm just saying no one has ever seen me and Wonder Woman in the same room together.\",\n",
        "    \"I'm not saying I'm Superman, I'm just saying no one has ever seen me and Superman in the same room together.\",\n",
        "    \"I'm not saying I'm Spider-Man, I'm just saying no one has ever seen me and Spider-Man in the same room together.\",\n",
        "    \"I'm not saying I'm Iron Man, I'm just saying no one has ever seen me and Iron Man in the same room together.\",\n",
        "    \"I'm not saying I'm Captain America, I'm just saying no one has ever seen me and Captain America in the same room together.\",\n",
        "    \"I'm not saying I'm Thor, I'm just saying no one has ever seen me and Thor in the same room together.\",\n",
        "    \"I'm not saying I'm the Hulk, I'm just saying no one has ever seen me and the Hulk in the same room together.\",\n",
        "    \"I'm not saying I'm Black Widow, I'm just saying no one has ever seen me and Black Widow in the same room together.\",\n",
        "    \"I'm not saying I'm Hawkeye, I'm just saying no one has ever seen me and Hawkeye in the same room together.\",\n",
        "    \"The cake is a lie.\",\n",
        "    \"All your base are belong to us.\",\n",
        "    \"It's dangerous to go alone! Take this.\",\n",
        "    \"Do a barrel roll!\",\n",
        "    \"The princess is in another castle.\",\n",
        "    \"You have died of dysentery.\",\n",
        "    \"Snake? Snake? Snaaaake!\",\n",
        "    \"War. War never changes.\",\n",
        "    \"Would you kindly?\",\n",
        "    \"Finish him!\",\n",
        "    \"Get over here!\",\n",
        "    \"Hadouken!\",\n",
        "    \"Fatality!\",\n",
        "    \"Leeeeeeeroy Jenkins!\",\n",
        "    \"Stay a while and listen!\",\n",
        "    \"You must construct additional pylons.\",\n",
        "    \"It's super effective!\",\n",
        "    \"A wild Pikachu appeared!\",\n",
        "    \"Gotta catch 'em all!\",\n",
        "    \"Do, or do not. There is no try.\",\n",
        "    \"These aren't the droids you're looking for.\",\n",
        "    \"I find your lack of faith disturbing.\",\n",
        "    \"Never tell me the odds.\",\n",
        "    \"I've got a bad feeling about this.\",\n",
        "    \"Use the Force, Luke.\",\n",
        "    \"The needs of the many outweigh the needs of the few.\",\n",
        "    \"Beam me up, Scotty.\",\n",
        "    \"Resistance is futile.\",\n",
        "    \"Make it so.\",\n",
        "    \"Space: the final frontier.\",\n",
        "    \"I'm a doctor, not a bricklayer!\",\n",
        "    \"Fascinating.\",\n",
        "    \"Engage.\",\n",
        "    \"Today is a good day to die!\",\n",
        "    \"These are the voyages of the starship Enterprise.\"\n",
        "]"
      ],
      "metadata": {
        "id": "akpU9F0h2_fg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Inference Test Helper Function\n",
        "\n",
        "We'll create a function that tests a few key inference related metrics:\n",
        "\n",
        "1. Time to First Token (TTFT): How long does it take before our endpoint starts returning tokens, TTFT is key in creating applications that *feel* responsive due to responses from LLMs typically being streamed to users as tokens are generated.\n",
        "2. Inter-Token Latency (ITL): Inter-Token Latency talks about the amount of time between tokens being generated. Lower ITL helps the response come through fast enough to keep up with typical reading speeds.\n",
        "3. Tokens Per Second (TPS): A classic metric that simply indicates how many Tokens are produced per second.\n",
        "\n",
        "Let's create this function below - and then use it evaluate our AWQ endpoint and our BNB endpoint."
      ],
      "metadata": {
        "id": "vSUim2Y07Vwf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import time\n",
        "from openai import OpenAI\n",
        "from typing import List, Dict\n",
        "from tqdm import tqdm\n",
        "\n",
        "def measure_endpoint_performance(endpoint_url: str, sentences: List[str]) -> Dict[str, float]:\n",
        "    client = OpenAI(\n",
        "        base_url=endpoint_url,\n",
        "        api_key=os.environ[\"HF_TOKEN\"]\n",
        "    )\n",
        "\n",
        "    total_time = 0\n",
        "    total_first_token_time = 0\n",
        "    total_tokens = 0\n",
        "    total_inter_token_time = 0\n",
        "    total_inter_token_intervals = 0\n",
        "\n",
        "    for sentence in tqdm(sentences):\n",
        "        start_time = time.time()\n",
        "        first_token_received = False\n",
        "        tokens_received = 0\n",
        "        last_token_time = start_time\n",
        "\n",
        "        chat_completion = client.chat.completions.create(\n",
        "            model=\"tgi\",\n",
        "            messages=[\n",
        "                {\n",
        "                    \"role\": \"user\",\n",
        "                    \"content\": sentence\n",
        "                }\n",
        "            ],\n",
        "            stream=True,\n",
        "            max_tokens=20\n",
        "        )\n",
        "\n",
        "        for message in chat_completion:\n",
        "            current_time = time.time()\n",
        "            if not first_token_received:\n",
        "                first_token_time = current_time - start_time\n",
        "                total_first_token_time += first_token_time\n",
        "                first_token_received = True\n",
        "            else:\n",
        "                inter_token_time = current_time - last_token_time\n",
        "                total_inter_token_time += inter_token_time\n",
        "                total_inter_token_intervals += 1\n",
        "\n",
        "            content = message.choices[0].delta.content\n",
        "            if content:\n",
        "                tokens_received += 1\n",
        "                last_token_time = current_time\n",
        "\n",
        "        request_time = time.time() - start_time\n",
        "        total_time += request_time\n",
        "        total_tokens += tokens_received\n",
        "\n",
        "    num_sentences = len(sentences)\n",
        "    average_time = total_time / num_sentences\n",
        "    average_first_token_time = total_first_token_time / num_sentences\n",
        "    average_tokens_per_second = total_tokens / total_time\n",
        "    average_inter_token_latency = total_inter_token_time / total_inter_token_intervals if total_inter_token_intervals > 0 else 0\n",
        "\n",
        "    return {\n",
        "        \"average_request_time\": average_time,\n",
        "        \"average_time_to_first_token\": average_first_token_time,\n",
        "        \"average_tokens_per_second\": average_tokens_per_second,\n",
        "        \"average_inter_token_latency\": average_inter_token_latency\n",
        "    }"
      ],
      "metadata": {
        "id": "CD4zAChU2F_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Bits and Bytes Endpoint Evaluation\n",
        "\n",
        "First, let's baseline with [Llama 3.1 8B Instruct](https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct) powered by BitsAndBytes quantization through TGI."
      ],
      "metadata": {
        "id": "qttmH8vr9F0T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bitsandbytes_endpoint_url = \"<< YOUR REGULAR MODEL HUGGINGFACE INFERENCE ENDPOINT HERE >>\" + \"/v1/\""
      ],
      "metadata": {
        "id": "YKUS--G23kW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = measure_endpoint_performance(bitsandbytes_endpoint_url, test_sentences)\n",
        "print(\"\\nResults:\")\n",
        "for key, value in results.items():\n",
        "    print(f\"{key}: {value:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I9lON9dR3sF8",
        "outputId": "e49bb420-1220-44d6-a6f5-f61e7804e3e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 103/103 [02:23<00:00,  1.39s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results:\n",
            "average_request_time: 1.39\n",
            "average_time_to_first_token: 0.14\n",
            "average_tokens_per_second: 13.93\n",
            "average_inter_token_latency: 0.07\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### GPTQ Evaluation\n",
        "\n",
        "We'll be using the [Hugging Quants\n",
        "Meta-Llama-3.1-8B-Instruct-GPTQ-INT4](https://huggingface.co/hugging-quants/Meta-Llama-3.1-8B-Instruct-GPTQ-INT4) model as our GPTQ test model.\n",
        "\n",
        "Given what we've learned about GPTQ - this endpoint should outperform our naive BitsAndBytes quantized endpoint."
      ],
      "metadata": {
        "id": "nud8k2bcAv_-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### GPTQ: Under the Hood\n",
        "\n",
        "The basic outline of what's happening in GPTQ is as follows:\n",
        "\n",
        "1. Start with a pre-trained language model\n",
        "2. For each layer:\n",
        "  - Compute an approximation of the layer's Hessian matrix\n",
        "  - Quantize weights column-by-column\n",
        "  - After each column, update remaining weights to compensate\n",
        "3. Use special tricks to make this efficient:\n",
        "  - Quantize in fixed order instead of greedy order\n",
        "  - Process weights in batches\n",
        "  - Use Cholesky decomposition for numerical stability\n",
        "4. Result: Compressed model that can run much faster\n",
        "\n",
        "#### Hessian Matrix:\n",
        "\n",
        "Okay, so that makes sense - but there's a question: What is the layer's \"Hessian matrix\"?\n",
        "\n",
        "In essence, we can think of the layer's \"Hessian Matrix\" as a map of how sensitive a layer's output is to changes in its weights. This gives us a matrix that corresponds to how much the output will change based on changes to each weight.\n",
        "\n",
        "The process described in GPTQ uses a fast approximation to get the Hessian Matrix and then uses that to determine how to compress (or quantize) the model's weights such that they don't mess up the model's outputs.\n",
        "\n",
        "So where a process like AWQ uses the activations to determine how each parameter (weight) impacts the outputs - GPTQ uses each layer's Hessian Matrix.\n",
        "\n"
      ],
      "metadata": {
        "id": "1bGxli4iRBlC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gptq_endpoint_url = \"<< YOUR GPTQ MODEL INFERENCE ENDPOINT URL HERE >>\" + \"/v1/\""
      ],
      "metadata": {
        "id": "qKkCXIoSBeUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = measure_endpoint_performance(gptq_endpoint_url, test_sentences)\n",
        "print(\"\\nResults:\")\n",
        "for key, value in results.items():\n",
        "    print(f\"{key}: {value:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVx1yus4BkTc",
        "outputId": "871b554d-c002-4b57-fc81-7259010ac692"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 103/103 [01:09<00:00,  1.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results:\n",
            "average_request_time: 0.67\n",
            "average_time_to_first_token: 0.29\n",
            "average_tokens_per_second: 28.58\n",
            "average_inter_token_latency: 0.02\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AWQ Evaluation\n",
        "\n",
        "We'll be using the [Hugging Quants\n",
        "Meta-Llama-3.1-8B-Instruct-AWQ-INT4](https://huggingface.co/hugging-quants/Meta-Llama-3.1-8B-Instruct-AWQ-INT4) as our AWQ test model.\n",
        "\n",
        "Given what we've learned about AWQ - this endpoint should outperform our naive BitsAndBytes quantized endpoint - let's test it out!"
      ],
      "metadata": {
        "id": "ISgV4L8H9mk4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### AWQ: Under the Hood\n",
        "\n",
        "There is a key set of assumptions that AWQ is working off of:\n",
        "\n",
        "1. Some weights are more important than other weights.\n",
        "2. That proportion of important weights is extremely small (~=1%)\n",
        "3. We are working with hardware optimzed for specific kinds of computations\n",
        "4. Moving things around in GPU memory is slow and inefficient for most use-cases"
      ],
      "metadata": {
        "id": "8dwrhnKhQ9jR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "awq_endpoint_url = \"<< YOUR AWQ MODEL INFERENCE ENDPOINT URL HERE >>\" + \"/v1/\""
      ],
      "metadata": {
        "id": "rJxFOgan20rL"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = measure_endpoint_performance(awq_endpoint_url, test_sentences)\n",
        "print(\"\\nResults:\")\n",
        "for key, value in results.items():\n",
        "    print(f\"{key}: {value:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v2Ck10K53Eo8",
        "outputId": "4324cc50-f439-4e1e-d38a-04a4ebb98e20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 103/103 [00:45<00:00,  2.25it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Results:\n",
            "average_request_time: 0.44\n",
            "average_time_to_first_token: 0.08\n",
            "average_tokens_per_second: 42.92\n",
            "average_inter_token_latency: 0.02\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### ❓ Question:\n",
        "\n",
        "Describe the difference in performance profiles between the three solutions."
      ],
      "metadata": {
        "id": "6Uo07EPZZX9J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Checkpoint Conversion\n",
        "\n",
        "For both the AWQ and GPTQ quantization strategies - there exist easy conversion strategies.\n",
        "\n",
        "We'll go over both of those strategies below."
      ],
      "metadata": {
        "id": "mfNYoFeDN6_M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using AutoAWQ to Convert a Model\n",
        "\n",
        "We'll see in the following step how easy it is to convert a model to AWQ by leveraging AutoAWQ.\n",
        "\n",
        "First, we'll need a model we wish to convert. We'll stick with Llama 3.1 8B Instruct for demonstration purposes.\n",
        "\n",
        "We'll start by setting some parameters that will help us define the resultant model:\n",
        "\n",
        "- `zero-point` - this indicates to use Zero-Point Quantization as our quantization strategy.\n",
        "  - `q = round((x / scale) + zero_point)`, this quantization strategy allows us to better represent numbers asymetrically around zero, meaning we can use unsigned 8bit integers to describe both positvie and negative weights.\n",
        "- `q_group_size` - like in BNB quantization, we quantize many weights under the same `scale` and `zero_point` to add additional efficiency during quanitzation without losing as much precision. These are sometimes called \"bins\" or \"blocks\".\n",
        "- `w_bit` - the size of the weight in bits\n",
        "\n"
      ],
      "metadata": {
        "id": "ULv33HnzA8IC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"meta-llama/Meta-Llama-3.1-8B-Instruct\"\n",
        "quant_path = \"hugging-quants/Meta-Llama-3.1-8B-Instruct-AWQ-INT4\"\n",
        "\n",
        "quant_config = {\n",
        "  \"zero_point\": True,\n",
        "  \"q_group_size\": 128,\n",
        "  \"w_bit\": 4,\n",
        "  \"version\": \"GEMM\",\n",
        "}"
      ],
      "metadata": {
        "id": "tx9yD8wrDpMR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from awq import AutoAWQForCausalLM\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "# Load model\n",
        "model = AutoAWQForCausalLM.from_pretrained(\n",
        "  model_path, low_cpu_mem_usage=True, use_cache=False, device_map=\"auto\",\n",
        ")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "\n",
        "# Quantize\n",
        "model.quantize(tokenizer, quant_config=quant_config)\n",
        "\n",
        "# Save quantized model\n",
        "model.save_quantized(quant_path)\n",
        "tokenizer.save_pretrained(quant_path)\n",
        "\n",
        "print(f'Model is quantized and saved at \"{quant_path}\"')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 205,
          "referenced_widgets": [
            "c290bd84649a45bc9a75468c8b6b2034",
            "5b46368e1e174dad981f62576c7a4155",
            "0f2b776edc304fda9b79b6223654d45c",
            "16b711896f2142bc98c6468a3126dba2",
            "15df3fd89de343c7af3b8cc0ce749070",
            "19c455966afb414d8c306982c2ca1dd9",
            "0fca593180af45c9b85f9bc84857194e",
            "e88202f07b87454091798e2bfe9200c3",
            "4f8ba98960454d74adfd1cf050fd7df1",
            "ef16ee7f377747bbacdba3bd2d9ccc9e",
            "fe74007752464ad6ba49ca40b88a28fb",
            "e466cf748f9241a8b185b8e802ea66de",
            "69c4016af38645cc9727246cdd687ca7",
            "6bbbe12a68a74994af20b97adde05ef6",
            "986b620e7cea4e16b86ce6eae493d9f2",
            "8ececf52fae14597b69b668ce791bdde",
            "dd72f1d38f4848e08458cbb5f586c14e",
            "3217a95296214972a64b02b452081da2",
            "dee59bb317bb44f9ad680c93f3e187df",
            "aaf1884238a8435b80a5d68925de3067",
            "7dd39c6ca4c9456589ee9b8846c5d6b6",
            "f333543b52454c5ea0b554b428d75117"
          ]
        },
        "id": "GTWEpsa8BGYw",
        "outputId": "a6ed36a2-1403-4eca-a573-1e1a5abd67df"
      },
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c290bd84649a45bc9a75468c8b6b2034",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 16 files:   0%|          | 0/16 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e466cf748f9241a8b185b8e802ea66de",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Repo card metadata block was not found. Setting CardData to empty.\n",
            "WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.\n",
            "AWQ:   0%|          | 0/32 [00:00<?, ?it/s]The attention layers in this model are transitioning from computing the RoPE embeddings internally through `position_ids` (2D tensor with the indexes of the tokens), to using externally computed `position_embeddings` (Tuple of tensors, containing cos and sin). In v4.45 `position_ids` will be removed and `position_embeddings` will be mandatory.\n",
            "AWQ: 100%|██████████| 32/32 [16:45<00:00, 31.43s/it]\n",
            "Note that `shard_checkpoint` is deprecated and will be removed in v4.44. We recommend you using split_torch_state_dict_into_shards from huggingface_hub library\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model is quantized and saved at \"hugging-quants/Meta-Llama-3.1-8B-Instruct-AWQ-INT4\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using GPTQModel to Convert a Model\n",
        "\n",
        "We'll see in the following step how easy it is to convert a model to GPTQ by leveraging [GPTQModel](https://github.com/ModelCloud/GPTQModel).\n",
        "\n",
        "First, we'll need a model we wish to convert. We'll stick with Llama 3.1 8B Instruct for demonstration purposes.\n",
        "\n",
        "We'll start by setting some parameters that will help us define the resultant model:\n",
        "\n",
        "- `bits` - the target bit width for the final quanitzed model\n",
        "- `group_size` - the number of weights to be quantized under a single scaling factor"
      ],
      "metadata": {
        "id": "4qj0bwAlPlC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from gptqmodel import GPTQModel, QuantizeConfig\n",
        "\n",
        "pretrained_model_dir = \"NousResearch/Meta-Llama-3.1-8B-Instruct\"\n",
        "quantized_model_dir = \"Meta-Llama-3.1-8B-Instruct-4bit\"\n",
        "\n",
        "quant_config = QuantizeConfig(\n",
        "    bits=4,\n",
        "    group_size=128,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29efc86a-a8b8-47e6-8a5c-5d7a78d5170b",
        "id": "PrwAvIA8PlC1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gptqmodel/nn_modules/triton_utils/dequant.py:123: FutureWarning: `torch.cuda.amp.custom_fwd(args...)` is deprecated. Please use `torch.amp.custom_fwd(args..., device_type='cuda')` instead.\n",
            "  def forward(ctx, input, qweight, scales, qzeros, g_idx, bits, maxq):\n",
            "/usr/local/lib/python3.10/dist-packages/gptqmodel/nn_modules/triton_utils/dequant.py:131: FutureWarning: `torch.cuda.amp.custom_bwd(args...)` is deprecated. Please use `torch.amp.custom_bwd(args..., device_type='cuda')` instead.\n",
            "  def backward(ctx, grad_output):\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "\n",
        "logging.basicConfig(\n",
        "    format=\"%(asctime)s %(levelname)s [%(name)s] %(message)s\", level=logging.INFO, datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
        ")"
      ],
      "metadata": {
        "id": "MiiRGTFZB4Zt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, TextGenerationPipeline\n",
        "\n",
        "# Load model\n",
        "model = GPTQModel.from_pretrained(pretrained_model_dir, quant_config)\n",
        "tokenizer = AutoTokenizer.from_pretrained(pretrained_model_dir, use_fast=True)\n",
        "calibration_dataset = [tokenizer(text) for text in test_sentences]\n",
        "\n",
        "# Quantize\n",
        "model.quantize(calibration_dataset)\n",
        "\n",
        "# Save quantized model\n",
        "model.save_quantized(quantized_model_dir)\n",
        "\n",
        "print(f'Model is quantized and saved at \"{quantized_model_dir}\"')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "a17134ebb18c4e24b18cc8383bdadfad",
            "37a9cbbb0dcd491892392508f263738e",
            "20e5e5ea6c4440f19df0385adacc75af",
            "ec1728dc15424286bb4cbe6896cbe281",
            "eb3e00e976054992aef546d8353988e6",
            "41873bcd56774689a47489f096544218",
            "c2fdedb17526439c8718f51ef5602261",
            "5438fc7c8cc14777843f3d9140655496",
            "05250a8946404ed9b1b397268b3f3dac",
            "413ea802400a4990bf0d248088dd23a8",
            "579164ac0bc7415d9e6bd2c3780fe923"
          ]
        },
        "outputId": "0f636dad-e746-449f-9add-111e4676a8bf",
        "id": "9bOeXn4PPlC2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a17134ebb18c4e24b18cc8383bdadfad"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING - Calibration dataset size should be greater than 256. Current size: 103.\n",
            "WARNING - The average length of input_ids of calibration_dataset should be greater than 256: actual avg: 10.320388349514563.\n",
            "WARNING - Model config does not have pad token mapped. Please pass in tokenizer to `quantize()` so GPTQModel can auto-select the best pad token.\n",
            "Quantizing self_attn.k_proj in layer 0 of 31:   0%|          | 0/32 [00:00<?, ?it/s]INFO - {'layer': 0, 'module': 'self_attn.k_proj', 'avg_loss': '0.00119', 'damp_percent': '0.00500', 'time': '3.234'}\n",
            "Quantizing self_attn.v_proj in layer 0 of 31:   0%|          | 0/32 [00:04<?, ?it/s]INFO - {'layer': 0, 'module': 'self_attn.v_proj', 'avg_loss': '0.00005', 'damp_percent': '0.00500', 'time': '1.608'}\n",
            "Quantizing self_attn.q_proj in layer 0 of 31:   0%|          | 0/32 [00:05<?, ?it/s]INFO - {'layer': 0, 'module': 'self_attn.q_proj', 'avg_loss': '0.00199', 'damp_percent': '0.00500', 'time': '1.643'}\n",
            "Quantizing self_attn.o_proj in layer 0 of 31:   0%|          | 0/32 [00:07<?, ?it/s]INFO - {'layer': 0, 'module': 'self_attn.o_proj', 'avg_loss': '0.00000', 'damp_percent': '0.00500', 'time': '1.620'}\n",
            "Quantizing mlp.up_proj in layer 0 of 31:   0%|          | 0/32 [00:09<?, ?it/s]     INFO - {'layer': 0, 'module': 'mlp.up_proj', 'avg_loss': '0.00368', 'damp_percent': '0.00500', 'time': '1.645'}\n",
            "Quantizing mlp.gate_proj in layer 0 of 31:   0%|          | 0/32 [00:11<?, ?it/s]INFO - {'layer': 0, 'module': 'mlp.gate_proj', 'avg_loss': '0.00435', 'damp_percent': '0.00500', 'time': '1.649'}\n",
            "Quantizing mlp.down_proj in layer 0 of 31:   0%|          | 0/32 [00:13<?, ?it/s]INFO - {'layer': 0, 'module': 'mlp.down_proj', 'avg_loss': '0.00005', 'damp_percent': '0.00500', 'time': '6.314'}\n",
            "Quantizing self_attn.k_proj in layer 1 of 31:   3%|▎         | 1/32 [00:20<10:24, 20.14s/it]INFO - {'layer': 1, 'module': 'self_attn.k_proj', 'avg_loss': '0.00238', 'damp_percent': '0.00500', 'time': '1.603'}\n",
            "Quantizing self_attn.v_proj in layer 1 of 31:   3%|▎         | 1/32 [00:22<10:24, 20.14s/it]INFO - {'layer': 1, 'module': 'self_attn.v_proj', 'avg_loss': '0.00019', 'damp_percent': '0.00500', 'time': '1.615'}\n",
            "Quantizing self_attn.q_proj in layer 1 of 31:   3%|▎         | 1/32 [00:23<10:24, 20.14s/it]INFO - {'layer': 1, 'module': 'self_attn.q_proj', 'avg_loss': '0.00471', 'damp_percent': '0.00500', 'time': '1.652'}\n",
            "Quantizing self_attn.o_proj in layer 1 of 31:   3%|▎         | 1/32 [00:25<10:24, 20.14s/it]INFO - {'layer': 1, 'module': 'self_attn.o_proj', 'avg_loss': '0.00001', 'damp_percent': '0.00500', 'time': '1.695'}\n",
            "Quantizing mlp.up_proj in layer 1 of 31:   3%|▎         | 1/32 [00:27<10:24, 20.14s/it]     INFO - {'layer': 1, 'module': 'mlp.up_proj', 'avg_loss': '0.00831', 'damp_percent': '0.00500', 'time': '1.646'}\n",
            "Quantizing mlp.gate_proj in layer 1 of 31:   3%|▎         | 1/32 [00:29<10:24, 20.14s/it]INFO - {'layer': 1, 'module': 'mlp.gate_proj', 'avg_loss': '0.00979', 'damp_percent': '0.00500', 'time': '1.669'}\n",
            "Quantizing mlp.down_proj in layer 1 of 31:   3%|▎         | 1/32 [00:31<10:24, 20.14s/it]INFO - {'layer': 1, 'module': 'mlp.down_proj', 'avg_loss': '0.84043', 'damp_percent': '0.00500', 'time': '6.209'}\n",
            "Quantizing self_attn.k_proj in layer 2 of 31:   6%|▋         | 2/32 [00:38<09:23, 18.77s/it]INFO - {'layer': 2, 'module': 'self_attn.k_proj', 'avg_loss': '0.01027', 'damp_percent': '0.00500', 'time': '1.614'}\n",
            "Quantizing self_attn.v_proj in layer 2 of 31:   6%|▋         | 2/32 [00:39<09:23, 18.77s/it]INFO - {'layer': 2, 'module': 'self_attn.v_proj', 'avg_loss': '0.00078', 'damp_percent': '0.00500', 'time': '1.643'}\n",
            "Quantizing self_attn.q_proj in layer 2 of 31:   6%|▋         | 2/32 [00:41<09:23, 18.77s/it]INFO - {'layer': 2, 'module': 'self_attn.q_proj', 'avg_loss': '0.01926', 'damp_percent': '0.00500', 'time': '1.697'}\n",
            "Quantizing self_attn.o_proj in layer 2 of 31:   6%|▋         | 2/32 [00:43<09:23, 18.77s/it]INFO - {'layer': 2, 'module': 'self_attn.o_proj', 'avg_loss': '0.00001', 'damp_percent': '0.00500', 'time': '1.641'}\n",
            "Quantizing mlp.up_proj in layer 2 of 31:   6%|▋         | 2/32 [00:45<09:23, 18.77s/it]     INFO - {'layer': 2, 'module': 'mlp.up_proj', 'avg_loss': '0.01392', 'damp_percent': '0.00500', 'time': '1.650'}\n",
            "Quantizing mlp.gate_proj in layer 2 of 31:   6%|▋         | 2/32 [00:46<09:23, 18.77s/it]INFO - {'layer': 2, 'module': 'mlp.gate_proj', 'avg_loss': '0.01725', 'damp_percent': '0.00500', 'time': '1.678'}\n",
            "Quantizing mlp.down_proj in layer 2 of 31:   6%|▋         | 2/32 [00:49<09:23, 18.77s/it]INFO - {'layer': 2, 'module': 'mlp.down_proj', 'avg_loss': '0.00002', 'damp_percent': '0.00500', 'time': '6.252'}\n",
            "Quantizing self_attn.k_proj in layer 3 of 31:   9%|▉         | 3/32 [00:56<08:52, 18.37s/it]INFO - {'layer': 3, 'module': 'self_attn.k_proj', 'avg_loss': '0.01386', 'damp_percent': '0.00500', 'time': '1.613'}\n",
            "Quantizing self_attn.v_proj in layer 3 of 31:   9%|▉         | 3/32 [00:57<08:52, 18.37s/it]INFO - {'layer': 3, 'module': 'self_attn.v_proj', 'avg_loss': '0.00147', 'damp_percent': '0.00500', 'time': '1.628'}\n",
            "Quantizing self_attn.q_proj in layer 3 of 31:   9%|▉         | 3/32 [00:59<08:52, 18.37s/it]INFO - {'layer': 3, 'module': 'self_attn.q_proj', 'avg_loss': '0.02667', 'damp_percent': '0.00500', 'time': '1.649'}\n",
            "Quantizing self_attn.o_proj in layer 3 of 31:   9%|▉         | 3/32 [01:01<08:52, 18.37s/it]INFO - {'layer': 3, 'module': 'self_attn.o_proj', 'avg_loss': '0.00002', 'damp_percent': '0.00500', 'time': '1.645'}\n",
            "Quantizing mlp.up_proj in layer 3 of 31:   9%|▉         | 3/32 [01:03<08:52, 18.37s/it]     INFO - {'layer': 3, 'module': 'mlp.up_proj', 'avg_loss': '0.01933', 'damp_percent': '0.00500', 'time': '1.658'}\n",
            "Quantizing mlp.gate_proj in layer 3 of 31:   9%|▉         | 3/32 [01:04<08:52, 18.37s/it]INFO - {'layer': 3, 'module': 'mlp.gate_proj', 'avg_loss': '0.02750', 'damp_percent': '0.00500', 'time': '1.672'}\n",
            "Quantizing mlp.down_proj in layer 3 of 31:   9%|▉         | 3/32 [01:06<08:52, 18.37s/it]INFO - {'layer': 3, 'module': 'mlp.down_proj', 'avg_loss': '0.00004', 'damp_percent': '0.00500', 'time': '6.234'}\n",
            "Quantizing self_attn.k_proj in layer 4 of 31:  12%|█▎        | 4/32 [01:13<08:28, 18.15s/it]INFO - {'layer': 4, 'module': 'self_attn.k_proj', 'avg_loss': '0.01120', 'damp_percent': '0.00500', 'time': '1.604'}\n",
            "Quantizing self_attn.v_proj in layer 4 of 31:  12%|█▎        | 4/32 [01:15<08:28, 18.15s/it]INFO - {'layer': 4, 'module': 'self_attn.v_proj', 'avg_loss': '0.00146', 'damp_percent': '0.00500', 'time': '1.640'}\n",
            "Quantizing self_attn.q_proj in layer 4 of 31:  12%|█▎        | 4/32 [01:17<08:28, 18.15s/it]INFO - {'layer': 4, 'module': 'self_attn.q_proj', 'avg_loss': '0.02152', 'damp_percent': '0.00500', 'time': '1.658'}\n",
            "Quantizing self_attn.o_proj in layer 4 of 31:  12%|█▎        | 4/32 [01:19<08:28, 18.15s/it]INFO - {'layer': 4, 'module': 'self_attn.o_proj', 'avg_loss': '0.00003', 'damp_percent': '0.00500', 'time': '1.617'}\n",
            "Quantizing mlp.up_proj in layer 4 of 31:  12%|█▎        | 4/32 [01:20<08:28, 18.15s/it]     INFO - {'layer': 4, 'module': 'mlp.up_proj', 'avg_loss': '0.02430', 'damp_percent': '0.00500', 'time': '1.647'}\n",
            "Quantizing mlp.gate_proj in layer 4 of 31:  12%|█▎        | 4/32 [01:22<08:28, 18.15s/it]INFO - {'layer': 4, 'module': 'mlp.gate_proj', 'avg_loss': '0.03881', 'damp_percent': '0.00500', 'time': '1.668'}\n",
            "Quantizing mlp.down_proj in layer 4 of 31:  12%|█▎        | 4/32 [01:24<08:28, 18.15s/it]INFO - {'layer': 4, 'module': 'mlp.down_proj', 'avg_loss': '0.00007', 'damp_percent': '0.00500', 'time': '6.310'}\n",
            "Quantizing self_attn.k_proj in layer 5 of 31:  16%|█▌        | 5/32 [01:31<08:07, 18.05s/it]INFO - {'layer': 5, 'module': 'self_attn.k_proj', 'avg_loss': '0.01470', 'damp_percent': '0.00500', 'time': '1.606'}\n",
            "Quantizing self_attn.v_proj in layer 5 of 31:  16%|█▌        | 5/32 [01:33<08:07, 18.05s/it]INFO - {'layer': 5, 'module': 'self_attn.v_proj', 'avg_loss': '0.00134', 'damp_percent': '0.00500', 'time': '1.625'}\n",
            "Quantizing self_attn.q_proj in layer 5 of 31:  16%|█▌        | 5/32 [01:35<08:07, 18.05s/it]INFO - {'layer': 5, 'module': 'self_attn.q_proj', 'avg_loss': '0.02803', 'damp_percent': '0.00500', 'time': '1.647'}\n",
            "Quantizing self_attn.o_proj in layer 5 of 31:  16%|█▌        | 5/32 [01:36<08:07, 18.05s/it]INFO - {'layer': 5, 'module': 'self_attn.o_proj', 'avg_loss': '0.00003', 'damp_percent': '0.00500', 'time': '1.621'}\n",
            "Quantizing mlp.up_proj in layer 5 of 31:  16%|█▌        | 5/32 [01:38<08:07, 18.05s/it]     INFO - {'layer': 5, 'module': 'mlp.up_proj', 'avg_loss': '0.02872', 'damp_percent': '0.00500', 'time': '1.651'}\n",
            "Quantizing mlp.gate_proj in layer 5 of 31:  16%|█▌        | 5/32 [01:40<08:07, 18.05s/it]INFO - {'layer': 5, 'module': 'mlp.gate_proj', 'avg_loss': '0.04535', 'damp_percent': '0.00500', 'time': '1.660'}\n",
            "Quantizing mlp.down_proj in layer 5 of 31:  16%|█▌        | 5/32 [01:42<08:07, 18.05s/it]INFO - {'layer': 5, 'module': 'mlp.down_proj', 'avg_loss': '0.00010', 'damp_percent': '0.00500', 'time': '6.214'}\n",
            "Quantizing self_attn.k_proj in layer 6 of 31:  19%|█▉        | 6/32 [01:49<07:46, 17.94s/it]INFO - {'layer': 6, 'module': 'self_attn.k_proj', 'avg_loss': '0.01468', 'damp_percent': '0.00500', 'time': '1.601'}\n",
            "Quantizing self_attn.v_proj in layer 6 of 31:  19%|█▉        | 6/32 [01:51<07:46, 17.94s/it]INFO - {'layer': 6, 'module': 'self_attn.v_proj', 'avg_loss': '0.00162', 'damp_percent': '0.00500', 'time': '1.629'}\n",
            "Quantizing self_attn.q_proj in layer 6 of 31:  19%|█▉        | 6/32 [01:52<07:46, 17.94s/it]INFO - {'layer': 6, 'module': 'self_attn.q_proj', 'avg_loss': '0.02949', 'damp_percent': '0.00500', 'time': '1.647'}\n",
            "Quantizing self_attn.o_proj in layer 6 of 31:  19%|█▉        | 6/32 [01:54<07:46, 17.94s/it]INFO - {'layer': 6, 'module': 'self_attn.o_proj', 'avg_loss': '0.00006', 'damp_percent': '0.00500', 'time': '1.634'}\n",
            "Quantizing mlp.up_proj in layer 6 of 31:  19%|█▉        | 6/32 [01:56<07:46, 17.94s/it]     INFO - {'layer': 6, 'module': 'mlp.up_proj', 'avg_loss': '0.03058', 'damp_percent': '0.00500', 'time': '1.655'}\n",
            "Quantizing mlp.gate_proj in layer 6 of 31:  19%|█▉        | 6/32 [01:58<07:46, 17.94s/it]INFO - {'layer': 6, 'module': 'mlp.gate_proj', 'avg_loss': '0.04875', 'damp_percent': '0.00500', 'time': '1.663'}\n",
            "Quantizing mlp.down_proj in layer 6 of 31:  19%|█▉        | 6/32 [02:00<07:46, 17.94s/it]INFO - {'layer': 6, 'module': 'mlp.down_proj', 'avg_loss': '0.00013', 'damp_percent': '0.00500', 'time': '6.217'}\n",
            "Quantizing self_attn.k_proj in layer 7 of 31:  22%|██▏       | 7/32 [02:07<07:27, 17.88s/it]INFO - {'layer': 7, 'module': 'self_attn.k_proj', 'avg_loss': '0.01619', 'damp_percent': '0.00500', 'time': '1.601'}\n",
            "Quantizing self_attn.v_proj in layer 7 of 31:  22%|██▏       | 7/32 [02:08<07:27, 17.88s/it]INFO - {'layer': 7, 'module': 'self_attn.v_proj', 'avg_loss': '0.00164', 'damp_percent': '0.00500', 'time': '1.613'}\n",
            "Quantizing self_attn.q_proj in layer 7 of 31:  22%|██▏       | 7/32 [02:10<07:27, 17.88s/it]INFO - {'layer': 7, 'module': 'self_attn.q_proj', 'avg_loss': '0.02940', 'damp_percent': '0.00500', 'time': '1.649'}\n",
            "Quantizing self_attn.o_proj in layer 7 of 31:  22%|██▏       | 7/32 [02:12<07:27, 17.88s/it]INFO - {'layer': 7, 'module': 'self_attn.o_proj', 'avg_loss': '0.00010', 'damp_percent': '0.00500', 'time': '1.632'}\n",
            "Quantizing mlp.up_proj in layer 7 of 31:  22%|██▏       | 7/32 [02:14<07:27, 17.88s/it]     INFO - {'layer': 7, 'module': 'mlp.up_proj', 'avg_loss': '0.03146', 'damp_percent': '0.00500', 'time': '1.669'}\n",
            "Quantizing mlp.gate_proj in layer 7 of 31:  22%|██▏       | 7/32 [02:15<07:27, 17.88s/it]INFO - {'layer': 7, 'module': 'mlp.gate_proj', 'avg_loss': '0.04726', 'damp_percent': '0.00500', 'time': '1.675'}\n",
            "Quantizing mlp.down_proj in layer 7 of 31:  22%|██▏       | 7/32 [02:18<07:27, 17.88s/it]INFO - {'layer': 7, 'module': 'mlp.down_proj', 'avg_loss': '0.00016', 'damp_percent': '0.00500', 'time': '6.232'}\n",
            "Quantizing self_attn.k_proj in layer 8 of 31:  25%|██▌       | 8/32 [02:25<07:08, 17.85s/it]INFO - {'layer': 8, 'module': 'self_attn.k_proj', 'avg_loss': '0.01793', 'damp_percent': '0.00500', 'time': '1.607'}\n",
            "Quantizing self_attn.v_proj in layer 8 of 31:  25%|██▌       | 8/32 [02:26<07:08, 17.85s/it]INFO - {'layer': 8, 'module': 'self_attn.v_proj', 'avg_loss': '0.00210', 'damp_percent': '0.00500', 'time': '1.622'}\n",
            "Quantizing self_attn.q_proj in layer 8 of 31:  25%|██▌       | 8/32 [02:28<07:08, 17.85s/it]INFO - {'layer': 8, 'module': 'self_attn.q_proj', 'avg_loss': '0.03302', 'damp_percent': '0.00500', 'time': '1.676'}\n",
            "Quantizing self_attn.o_proj in layer 8 of 31:  25%|██▌       | 8/32 [02:30<07:08, 17.85s/it]INFO - {'layer': 8, 'module': 'self_attn.o_proj', 'avg_loss': '0.00012', 'damp_percent': '0.00500', 'time': '1.622'}\n",
            "Quantizing mlp.up_proj in layer 8 of 31:  25%|██▌       | 8/32 [02:32<07:08, 17.85s/it]     INFO - {'layer': 8, 'module': 'mlp.up_proj', 'avg_loss': '0.03190', 'damp_percent': '0.00500', 'time': '1.643'}\n",
            "Quantizing mlp.gate_proj in layer 8 of 31:  25%|██▌       | 8/32 [02:33<07:08, 17.85s/it]INFO - {'layer': 8, 'module': 'mlp.gate_proj', 'avg_loss': '0.04822', 'damp_percent': '0.00500', 'time': '1.664'}\n",
            "Quantizing mlp.down_proj in layer 8 of 31:  25%|██▌       | 8/32 [02:35<07:08, 17.85s/it]INFO - {'layer': 8, 'module': 'mlp.down_proj', 'avg_loss': '0.00015', 'damp_percent': '0.00500', 'time': '6.257'}\n",
            "Quantizing self_attn.k_proj in layer 9 of 31:  28%|██▊       | 9/32 [02:42<06:50, 17.84s/it]INFO - {'layer': 9, 'module': 'self_attn.k_proj', 'avg_loss': '0.01798', 'damp_percent': '0.00500', 'time': '1.608'}\n",
            "Quantizing self_attn.v_proj in layer 9 of 31:  28%|██▊       | 9/32 [02:44<06:50, 17.84s/it]INFO - {'layer': 9, 'module': 'self_attn.v_proj', 'avg_loss': '0.00277', 'damp_percent': '0.00500', 'time': '1.603'}\n",
            "Quantizing self_attn.q_proj in layer 9 of 31:  28%|██▊       | 9/32 [02:46<06:50, 17.84s/it]INFO - {'layer': 9, 'module': 'self_attn.q_proj', 'avg_loss': '0.03262', 'damp_percent': '0.00500', 'time': '1.657'}\n",
            "Quantizing self_attn.o_proj in layer 9 of 31:  28%|██▊       | 9/32 [02:47<06:50, 17.84s/it]INFO - {'layer': 9, 'module': 'self_attn.o_proj', 'avg_loss': '0.00014', 'damp_percent': '0.00500', 'time': '1.647'}\n",
            "Quantizing mlp.up_proj in layer 9 of 31:  28%|██▊       | 9/32 [02:49<06:50, 17.84s/it]     INFO - {'layer': 9, 'module': 'mlp.up_proj', 'avg_loss': '0.03147', 'damp_percent': '0.00500', 'time': '1.667'}\n",
            "Quantizing mlp.gate_proj in layer 9 of 31:  28%|██▊       | 9/32 [02:51<06:50, 17.84s/it]INFO - {'layer': 9, 'module': 'mlp.gate_proj', 'avg_loss': '0.04817', 'damp_percent': '0.00500', 'time': '1.678'}\n",
            "Quantizing mlp.down_proj in layer 9 of 31:  28%|██▊       | 9/32 [02:53<06:50, 17.84s/it]INFO - {'layer': 9, 'module': 'mlp.down_proj', 'avg_loss': '0.00015', 'damp_percent': '0.00500', 'time': '6.253'}\n",
            "Quantizing self_attn.k_proj in layer 10 of 31:  31%|███▏      | 10/32 [03:00<06:32, 17.84s/it]INFO - {'layer': 10, 'module': 'self_attn.k_proj', 'avg_loss': '0.01924', 'damp_percent': '0.00500', 'time': '1.620'}\n",
            "Quantizing self_attn.v_proj in layer 10 of 31:  31%|███▏      | 10/32 [03:02<06:32, 17.84s/it]INFO - {'layer': 10, 'module': 'self_attn.v_proj', 'avg_loss': '0.00217', 'damp_percent': '0.00500', 'time': '1.624'}\n",
            "Quantizing self_attn.q_proj in layer 10 of 31:  31%|███▏      | 10/32 [03:04<06:32, 17.84s/it]INFO - {'layer': 10, 'module': 'self_attn.q_proj', 'avg_loss': '0.03551', 'damp_percent': '0.00500', 'time': '1.660'}\n",
            "Quantizing self_attn.o_proj in layer 10 of 31:  31%|███▏      | 10/32 [03:05<06:32, 17.84s/it]INFO - {'layer': 10, 'module': 'self_attn.o_proj', 'avg_loss': '0.00012', 'damp_percent': '0.00500', 'time': '1.624'}\n",
            "Quantizing mlp.up_proj in layer 10 of 31:  31%|███▏      | 10/32 [03:07<06:32, 17.84s/it]     INFO - {'layer': 10, 'module': 'mlp.up_proj', 'avg_loss': '0.03116', 'damp_percent': '0.00500', 'time': '1.651'}\n",
            "Quantizing mlp.gate_proj in layer 10 of 31:  31%|███▏      | 10/32 [03:09<06:32, 17.84s/it]INFO - {'layer': 10, 'module': 'mlp.gate_proj', 'avg_loss': '0.04442', 'damp_percent': '0.00500', 'time': '1.675'}\n",
            "Quantizing mlp.down_proj in layer 10 of 31:  31%|███▏      | 10/32 [03:11<06:32, 17.84s/it]INFO - {'layer': 10, 'module': 'mlp.down_proj', 'avg_loss': '0.00017', 'damp_percent': '0.00500', 'time': '6.284'}\n",
            "Quantizing self_attn.k_proj in layer 11 of 31:  34%|███▍      | 11/32 [03:18<06:14, 17.85s/it]INFO - {'layer': 11, 'module': 'self_attn.k_proj', 'avg_loss': '0.01967', 'damp_percent': '0.00500', 'time': '1.605'}\n",
            "Quantizing self_attn.v_proj in layer 11 of 31:  34%|███▍      | 11/32 [03:20<06:14, 17.85s/it]INFO - {'layer': 11, 'module': 'self_attn.v_proj', 'avg_loss': '0.00211', 'damp_percent': '0.00500', 'time': '1.615'}\n",
            "Quantizing self_attn.q_proj in layer 11 of 31:  34%|███▍      | 11/32 [03:21<06:14, 17.85s/it]INFO - {'layer': 11, 'module': 'self_attn.q_proj', 'avg_loss': '0.03333', 'damp_percent': '0.00500', 'time': '1.648'}\n",
            "Quantizing self_attn.o_proj in layer 11 of 31:  34%|███▍      | 11/32 [03:23<06:14, 17.85s/it]INFO - {'layer': 11, 'module': 'self_attn.o_proj', 'avg_loss': '0.00015', 'damp_percent': '0.00500', 'time': '1.649'}\n",
            "Quantizing mlp.up_proj in layer 11 of 31:  34%|███▍      | 11/32 [03:25<06:14, 17.85s/it]     INFO - {'layer': 11, 'module': 'mlp.up_proj', 'avg_loss': '0.03168', 'damp_percent': '0.00500', 'time': '1.662'}\n",
            "Quantizing mlp.gate_proj in layer 11 of 31:  34%|███▍      | 11/32 [03:27<06:14, 17.85s/it]INFO - {'layer': 11, 'module': 'mlp.gate_proj', 'avg_loss': '0.04335', 'damp_percent': '0.00500', 'time': '1.662'}\n",
            "Quantizing mlp.down_proj in layer 11 of 31:  34%|███▍      | 11/32 [03:29<06:14, 17.85s/it]INFO - {'layer': 11, 'module': 'mlp.down_proj', 'avg_loss': '0.00016', 'damp_percent': '0.00500', 'time': '6.254'}\n",
            "Quantizing self_attn.k_proj in layer 12 of 31:  38%|███▊      | 12/32 [03:36<05:56, 17.84s/it]INFO - {'layer': 12, 'module': 'self_attn.k_proj', 'avg_loss': '0.01659', 'damp_percent': '0.00500', 'time': '1.610'}\n",
            "Quantizing self_attn.v_proj in layer 12 of 31:  38%|███▊      | 12/32 [03:38<05:56, 17.84s/it]INFO - {'layer': 12, 'module': 'self_attn.v_proj', 'avg_loss': '0.00256', 'damp_percent': '0.00500', 'time': '1.615'}\n",
            "Quantizing self_attn.q_proj in layer 12 of 31:  38%|███▊      | 12/32 [03:39<05:56, 17.84s/it]INFO - {'layer': 12, 'module': 'self_attn.q_proj', 'avg_loss': '0.03003', 'damp_percent': '0.00500', 'time': '1.650'}\n",
            "Quantizing self_attn.o_proj in layer 12 of 31:  38%|███▊      | 12/32 [03:41<05:56, 17.84s/it]INFO - {'layer': 12, 'module': 'self_attn.o_proj', 'avg_loss': '0.00018', 'damp_percent': '0.00500', 'time': '1.646'}\n",
            "Quantizing mlp.up_proj in layer 12 of 31:  38%|███▊      | 12/32 [03:43<05:56, 17.84s/it]     INFO - {'layer': 12, 'module': 'mlp.up_proj', 'avg_loss': '0.03084', 'damp_percent': '0.00500', 'time': '1.686'}\n",
            "Quantizing mlp.gate_proj in layer 12 of 31:  38%|███▊      | 12/32 [03:45<05:56, 17.84s/it]INFO - {'layer': 12, 'module': 'mlp.gate_proj', 'avg_loss': '0.03949', 'damp_percent': '0.00500', 'time': '1.674'}\n",
            "Quantizing mlp.down_proj in layer 12 of 31:  38%|███▊      | 12/32 [03:47<05:56, 17.84s/it]INFO - {'layer': 12, 'module': 'mlp.down_proj', 'avg_loss': '0.00017', 'damp_percent': '0.00500', 'time': '6.289'}\n",
            "Quantizing self_attn.k_proj in layer 13 of 31:  41%|████      | 13/32 [03:54<05:39, 17.86s/it]INFO - {'layer': 13, 'module': 'self_attn.k_proj', 'avg_loss': '0.02102', 'damp_percent': '0.00500', 'time': '1.626'}\n",
            "Quantizing self_attn.v_proj in layer 13 of 31:  41%|████      | 13/32 [03:56<05:39, 17.86s/it]INFO - {'layer': 13, 'module': 'self_attn.v_proj', 'avg_loss': '0.00273', 'damp_percent': '0.00500', 'time': '1.644'}\n",
            "Quantizing self_attn.q_proj in layer 13 of 31:  41%|████      | 13/32 [03:57<05:39, 17.86s/it]INFO - {'layer': 13, 'module': 'self_attn.q_proj', 'avg_loss': '0.03727', 'damp_percent': '0.00500', 'time': '1.675'}\n",
            "Quantizing self_attn.o_proj in layer 13 of 31:  41%|████      | 13/32 [03:59<05:39, 17.86s/it]INFO - {'layer': 13, 'module': 'self_attn.o_proj', 'avg_loss': '0.00015', 'damp_percent': '0.00500', 'time': '1.643'}\n",
            "Quantizing mlp.up_proj in layer 13 of 31:  41%|████      | 13/32 [04:01<05:39, 17.86s/it]     INFO - {'layer': 13, 'module': 'mlp.up_proj', 'avg_loss': '0.03224', 'damp_percent': '0.00500', 'time': '1.673'}\n",
            "Quantizing mlp.gate_proj in layer 13 of 31:  41%|████      | 13/32 [04:03<05:39, 17.86s/it]INFO - {'layer': 13, 'module': 'mlp.gate_proj', 'avg_loss': '0.04095', 'damp_percent': '0.00500', 'time': '1.690'}\n",
            "Quantizing mlp.down_proj in layer 13 of 31:  41%|████      | 13/32 [04:05<05:39, 17.86s/it]INFO - {'layer': 13, 'module': 'mlp.down_proj', 'avg_loss': '0.00019', 'damp_percent': '0.00500', 'time': '6.347'}\n",
            "Quantizing self_attn.k_proj in layer 14 of 31:  44%|████▍     | 14/32 [04:12<05:22, 17.91s/it]INFO - {'layer': 14, 'module': 'self_attn.k_proj', 'avg_loss': '0.02097', 'damp_percent': '0.00500', 'time': '1.633'}\n",
            "Quantizing self_attn.v_proj in layer 14 of 31:  44%|████▍     | 14/32 [04:14<05:22, 17.91s/it]INFO - {'layer': 14, 'module': 'self_attn.v_proj', 'avg_loss': '0.00269', 'damp_percent': '0.00500', 'time': '1.623'}\n",
            "Quantizing self_attn.q_proj in layer 14 of 31:  44%|████▍     | 14/32 [04:15<05:22, 17.91s/it]INFO - {'layer': 14, 'module': 'self_attn.q_proj', 'avg_loss': '0.03636', 'damp_percent': '0.00500', 'time': '1.670'}\n",
            "Quantizing self_attn.o_proj in layer 14 of 31:  44%|████▍     | 14/32 [04:17<05:22, 17.91s/it]INFO - {'layer': 14, 'module': 'self_attn.o_proj', 'avg_loss': '0.00018', 'damp_percent': '0.00500', 'time': '1.644'}\n",
            "Quantizing mlp.up_proj in layer 14 of 31:  44%|████▍     | 14/32 [04:19<05:22, 17.91s/it]     INFO - {'layer': 14, 'module': 'mlp.up_proj', 'avg_loss': '0.03487', 'damp_percent': '0.00500', 'time': '1.653'}\n",
            "Quantizing mlp.gate_proj in layer 14 of 31:  44%|████▍     | 14/32 [04:21<05:22, 17.91s/it]INFO - {'layer': 14, 'module': 'mlp.gate_proj', 'avg_loss': '0.04589', 'damp_percent': '0.00500', 'time': '1.701'}\n",
            "Quantizing mlp.down_proj in layer 14 of 31:  44%|████▍     | 14/32 [04:23<05:22, 17.91s/it]INFO - {'layer': 14, 'module': 'mlp.down_proj', 'avg_loss': '0.00024', 'damp_percent': '0.00500', 'time': '6.262'}\n",
            "Quantizing self_attn.k_proj in layer 15 of 31:  47%|████▋     | 15/32 [04:30<05:04, 17.92s/it]INFO - {'layer': 15, 'module': 'self_attn.k_proj', 'avg_loss': '0.02006', 'damp_percent': '0.00500', 'time': '1.601'}\n",
            "Quantizing self_attn.v_proj in layer 15 of 31:  47%|████▋     | 15/32 [04:31<05:04, 17.92s/it]INFO - {'layer': 15, 'module': 'self_attn.v_proj', 'avg_loss': '0.00311', 'damp_percent': '0.00500', 'time': '1.697'}\n",
            "Quantizing self_attn.q_proj in layer 15 of 31:  47%|████▋     | 15/32 [04:33<05:04, 17.92s/it]INFO - {'layer': 15, 'module': 'self_attn.q_proj', 'avg_loss': '0.04323', 'damp_percent': '0.00500', 'time': '1.673'}\n",
            "Quantizing self_attn.o_proj in layer 15 of 31:  47%|████▋     | 15/32 [04:35<05:04, 17.92s/it]INFO - {'layer': 15, 'module': 'self_attn.o_proj', 'avg_loss': '0.00018', 'damp_percent': '0.00500', 'time': '1.634'}\n",
            "Quantizing mlp.up_proj in layer 15 of 31:  47%|████▋     | 15/32 [04:37<05:04, 17.92s/it]     INFO - {'layer': 15, 'module': 'mlp.up_proj', 'avg_loss': '0.03869', 'damp_percent': '0.00500', 'time': '1.662'}\n",
            "Quantizing mlp.gate_proj in layer 15 of 31:  47%|████▋     | 15/32 [04:39<05:04, 17.92s/it]INFO - {'layer': 15, 'module': 'mlp.gate_proj', 'avg_loss': '0.05388', 'damp_percent': '0.00500', 'time': '1.667'}\n",
            "Quantizing mlp.down_proj in layer 15 of 31:  47%|████▋     | 15/32 [04:41<05:04, 17.92s/it]INFO - {'layer': 15, 'module': 'mlp.down_proj', 'avg_loss': '0.00030', 'damp_percent': '0.00500', 'time': '6.266'}\n",
            "Quantizing self_attn.k_proj in layer 16 of 31:  50%|█████     | 16/32 [04:48<04:46, 17.92s/it]INFO - {'layer': 16, 'module': 'self_attn.k_proj', 'avg_loss': '0.02000', 'damp_percent': '0.00500', 'time': '1.615'}\n",
            "Quantizing self_attn.v_proj in layer 16 of 31:  50%|█████     | 16/32 [04:49<04:46, 17.92s/it]INFO - {'layer': 16, 'module': 'self_attn.v_proj', 'avg_loss': '0.00263', 'damp_percent': '0.00500', 'time': '1.623'}\n",
            "Quantizing self_attn.q_proj in layer 16 of 31:  50%|█████     | 16/32 [04:51<04:46, 17.92s/it]INFO - {'layer': 16, 'module': 'self_attn.q_proj', 'avg_loss': '0.03986', 'damp_percent': '0.00500', 'time': '1.666'}\n",
            "Quantizing self_attn.o_proj in layer 16 of 31:  50%|█████     | 16/32 [04:53<04:46, 17.92s/it]INFO - {'layer': 16, 'module': 'self_attn.o_proj', 'avg_loss': '0.00018', 'damp_percent': '0.00500', 'time': '1.630'}\n",
            "Quantizing mlp.up_proj in layer 16 of 31:  50%|█████     | 16/32 [04:55<04:46, 17.92s/it]     INFO - {'layer': 16, 'module': 'mlp.up_proj', 'avg_loss': '0.04260', 'damp_percent': '0.00500', 'time': '1.683'}\n",
            "Quantizing mlp.gate_proj in layer 16 of 31:  50%|█████     | 16/32 [04:56<04:46, 17.92s/it]INFO - {'layer': 16, 'module': 'mlp.gate_proj', 'avg_loss': '0.06429', 'damp_percent': '0.00500', 'time': '1.694'}\n",
            "Quantizing mlp.down_proj in layer 16 of 31:  50%|█████     | 16/32 [04:59<04:46, 17.92s/it]INFO - {'layer': 16, 'module': 'mlp.down_proj', 'avg_loss': '0.00035', 'damp_percent': '0.00500', 'time': '6.264'}\n",
            "Quantizing self_attn.k_proj in layer 17 of 31:  53%|█████▎    | 17/32 [05:06<04:28, 17.91s/it]INFO - {'layer': 17, 'module': 'self_attn.k_proj', 'avg_loss': '0.02126', 'damp_percent': '0.00500', 'time': '1.604'}\n",
            "Quantizing self_attn.v_proj in layer 17 of 31:  53%|█████▎    | 17/32 [05:07<04:28, 17.91s/it]INFO - {'layer': 17, 'module': 'self_attn.v_proj', 'avg_loss': '0.00350', 'damp_percent': '0.00500', 'time': '1.638'}\n",
            "Quantizing self_attn.q_proj in layer 17 of 31:  53%|█████▎    | 17/32 [05:09<04:28, 17.91s/it]INFO - {'layer': 17, 'module': 'self_attn.q_proj', 'avg_loss': '0.04381', 'damp_percent': '0.00500', 'time': '1.663'}\n",
            "Quantizing self_attn.o_proj in layer 17 of 31:  53%|█████▎    | 17/32 [05:11<04:28, 17.91s/it]INFO - {'layer': 17, 'module': 'self_attn.o_proj', 'avg_loss': '0.00012', 'damp_percent': '0.00500', 'time': '1.638'}\n",
            "Quantizing mlp.up_proj in layer 17 of 31:  53%|█████▎    | 17/32 [05:13<04:28, 17.91s/it]     INFO - {'layer': 17, 'module': 'mlp.up_proj', 'avg_loss': '0.04671', 'damp_percent': '0.00500', 'time': '1.655'}\n",
            "Quantizing mlp.gate_proj in layer 17 of 31:  53%|█████▎    | 17/32 [05:14<04:28, 17.91s/it]INFO - {'layer': 17, 'module': 'mlp.gate_proj', 'avg_loss': '0.07192', 'damp_percent': '0.00500', 'time': '1.666'}\n",
            "Quantizing mlp.down_proj in layer 17 of 31:  53%|█████▎    | 17/32 [05:16<04:28, 17.91s/it]INFO - {'layer': 17, 'module': 'mlp.down_proj', 'avg_loss': '0.00042', 'damp_percent': '0.00500', 'time': '6.274'}\n",
            "Quantizing self_attn.k_proj in layer 18 of 31:  56%|█████▋    | 18/32 [05:24<04:10, 17.90s/it]INFO - {'layer': 18, 'module': 'self_attn.k_proj', 'avg_loss': '0.02425', 'damp_percent': '0.00500', 'time': '1.604'}\n",
            "Quantizing self_attn.v_proj in layer 18 of 31:  56%|█████▋    | 18/32 [05:25<04:10, 17.90s/it]INFO - {'layer': 18, 'module': 'self_attn.v_proj', 'avg_loss': '0.00311', 'damp_percent': '0.00500', 'time': '1.616'}\n",
            "Quantizing self_attn.q_proj in layer 18 of 31:  56%|█████▋    | 18/32 [05:27<04:10, 17.90s/it]INFO - {'layer': 18, 'module': 'self_attn.q_proj', 'avg_loss': '0.04720', 'damp_percent': '0.00500', 'time': '1.656'}\n",
            "Quantizing self_attn.o_proj in layer 18 of 31:  56%|█████▋    | 18/32 [05:29<04:10, 17.90s/it]INFO - {'layer': 18, 'module': 'self_attn.o_proj', 'avg_loss': '0.00009', 'damp_percent': '0.00500', 'time': '1.627'}\n",
            "Quantizing mlp.up_proj in layer 18 of 31:  56%|█████▋    | 18/32 [05:30<04:10, 17.90s/it]     INFO - {'layer': 18, 'module': 'mlp.up_proj', 'avg_loss': '0.05035', 'damp_percent': '0.00500', 'time': '1.667'}\n",
            "Quantizing mlp.gate_proj in layer 18 of 31:  56%|█████▋    | 18/32 [05:32<04:10, 17.90s/it]INFO - {'layer': 18, 'module': 'mlp.gate_proj', 'avg_loss': '0.07981', 'damp_percent': '0.00500', 'time': '1.741'}\n",
            "Quantizing mlp.down_proj in layer 18 of 31:  56%|█████▋    | 18/32 [05:34<04:10, 17.90s/it]INFO - {'layer': 18, 'module': 'mlp.down_proj', 'avg_loss': '0.00044', 'damp_percent': '0.00500', 'time': '6.248'}\n",
            "Quantizing self_attn.k_proj in layer 19 of 31:  59%|█████▉    | 19/32 [05:41<03:52, 17.89s/it]INFO - {'layer': 19, 'module': 'self_attn.k_proj', 'avg_loss': '0.02354', 'damp_percent': '0.00500', 'time': '1.620'}\n",
            "Quantizing self_attn.v_proj in layer 19 of 31:  59%|█████▉    | 19/32 [05:43<03:52, 17.89s/it]INFO - {'layer': 19, 'module': 'self_attn.v_proj', 'avg_loss': '0.00364', 'damp_percent': '0.00500', 'time': '1.623'}\n",
            "Quantizing self_attn.q_proj in layer 19 of 31:  59%|█████▉    | 19/32 [05:45<03:52, 17.89s/it]INFO - {'layer': 19, 'module': 'self_attn.q_proj', 'avg_loss': '0.04848', 'damp_percent': '0.00500', 'time': '1.647'}\n",
            "Quantizing self_attn.o_proj in layer 19 of 31:  59%|█████▉    | 19/32 [05:46<03:52, 17.89s/it]INFO - {'layer': 19, 'module': 'self_attn.o_proj', 'avg_loss': '0.00007', 'damp_percent': '0.00500', 'time': '1.640'}\n",
            "Quantizing mlp.up_proj in layer 19 of 31:  59%|█████▉    | 19/32 [05:48<03:52, 17.89s/it]     INFO - {'layer': 19, 'module': 'mlp.up_proj', 'avg_loss': '0.05403', 'damp_percent': '0.00500', 'time': '1.648'}\n",
            "Quantizing mlp.gate_proj in layer 19 of 31:  59%|█████▉    | 19/32 [05:50<03:52, 17.89s/it]INFO - {'layer': 19, 'module': 'mlp.gate_proj', 'avg_loss': '0.08745', 'damp_percent': '0.00500', 'time': '1.663'}\n",
            "Quantizing mlp.down_proj in layer 19 of 31:  59%|█████▉    | 19/32 [05:52<03:52, 17.89s/it]INFO - {'layer': 19, 'module': 'mlp.down_proj', 'avg_loss': '0.00048', 'damp_percent': '0.00500', 'time': '6.256'}\n",
            "Quantizing self_attn.k_proj in layer 20 of 31:  62%|██████▎   | 20/32 [05:59<03:34, 17.87s/it]INFO - {'layer': 20, 'module': 'self_attn.k_proj', 'avg_loss': '0.02356', 'damp_percent': '0.00500', 'time': '1.597'}\n",
            "Quantizing self_attn.v_proj in layer 20 of 31:  62%|██████▎   | 20/32 [06:01<03:34, 17.87s/it]INFO - {'layer': 20, 'module': 'self_attn.v_proj', 'avg_loss': '0.00422', 'damp_percent': '0.00500', 'time': '1.600'}\n",
            "Quantizing self_attn.q_proj in layer 20 of 31:  62%|██████▎   | 20/32 [06:03<03:34, 17.87s/it]INFO - {'layer': 20, 'module': 'self_attn.q_proj', 'avg_loss': '0.04948', 'damp_percent': '0.00500', 'time': '1.629'}\n",
            "Quantizing self_attn.o_proj in layer 20 of 31:  62%|██████▎   | 20/32 [06:04<03:34, 17.87s/it]INFO - {'layer': 20, 'module': 'self_attn.o_proj', 'avg_loss': '0.00009', 'damp_percent': '0.00500', 'time': '1.624'}\n",
            "Quantizing mlp.up_proj in layer 20 of 31:  62%|██████▎   | 20/32 [06:06<03:34, 17.87s/it]     INFO - {'layer': 20, 'module': 'mlp.up_proj', 'avg_loss': '0.05972', 'damp_percent': '0.00500', 'time': '1.661'}\n",
            "Quantizing mlp.gate_proj in layer 20 of 31:  62%|██████▎   | 20/32 [06:08<03:34, 17.87s/it]INFO - {'layer': 20, 'module': 'mlp.gate_proj', 'avg_loss': '0.09566', 'damp_percent': '0.00500', 'time': '1.681'}\n",
            "Quantizing mlp.down_proj in layer 20 of 31:  62%|██████▎   | 20/32 [06:10<03:34, 17.87s/it]INFO - {'layer': 20, 'module': 'mlp.down_proj', 'avg_loss': '0.00052', 'damp_percent': '0.00500', 'time': '6.237'}\n",
            "Quantizing self_attn.k_proj in layer 21 of 31:  66%|██████▌   | 21/32 [06:17<03:16, 17.87s/it]INFO - {'layer': 21, 'module': 'self_attn.k_proj', 'avg_loss': '0.02444', 'damp_percent': '0.00500', 'time': '1.627'}\n",
            "Quantizing self_attn.v_proj in layer 21 of 31:  66%|██████▌   | 21/32 [06:19<03:16, 17.87s/it]INFO - {'layer': 21, 'module': 'self_attn.v_proj', 'avg_loss': '0.00458', 'damp_percent': '0.00500', 'time': '1.623'}\n",
            "Quantizing self_attn.q_proj in layer 21 of 31:  66%|██████▌   | 21/32 [06:20<03:16, 17.87s/it]INFO - {'layer': 21, 'module': 'self_attn.q_proj', 'avg_loss': '0.04822', 'damp_percent': '0.00500', 'time': '1.659'}\n",
            "Quantizing self_attn.o_proj in layer 21 of 31:  66%|██████▌   | 21/32 [06:22<03:16, 17.87s/it]INFO - {'layer': 21, 'module': 'self_attn.o_proj', 'avg_loss': '0.00013', 'damp_percent': '0.00500', 'time': '1.629'}\n",
            "Quantizing mlp.up_proj in layer 21 of 31:  66%|██████▌   | 21/32 [06:24<03:16, 17.87s/it]     INFO - {'layer': 21, 'module': 'mlp.up_proj', 'avg_loss': '0.06599', 'damp_percent': '0.00500', 'time': '1.650'}\n",
            "Quantizing mlp.gate_proj in layer 21 of 31:  66%|██████▌   | 21/32 [06:26<03:16, 17.87s/it]INFO - {'layer': 21, 'module': 'mlp.gate_proj', 'avg_loss': '0.10653', 'damp_percent': '0.00500', 'time': '1.670'}\n",
            "Quantizing mlp.down_proj in layer 21 of 31:  66%|██████▌   | 21/32 [06:28<03:16, 17.87s/it]INFO - {'layer': 21, 'module': 'mlp.down_proj', 'avg_loss': '0.00060', 'damp_percent': '0.00500', 'time': '6.253'}\n",
            "Quantizing self_attn.k_proj in layer 22 of 31:  69%|██████▉   | 22/32 [06:35<02:58, 17.86s/it]INFO - {'layer': 22, 'module': 'self_attn.k_proj', 'avg_loss': '0.02509', 'damp_percent': '0.00500', 'time': '1.609'}\n",
            "Quantizing self_attn.v_proj in layer 22 of 31:  69%|██████▉   | 22/32 [06:37<02:58, 17.86s/it]INFO - {'layer': 22, 'module': 'self_attn.v_proj', 'avg_loss': '0.00537', 'damp_percent': '0.00500', 'time': '1.616'}\n",
            "Quantizing self_attn.q_proj in layer 22 of 31:  69%|██████▉   | 22/32 [06:38<02:58, 17.86s/it]INFO - {'layer': 22, 'module': 'self_attn.q_proj', 'avg_loss': '0.04935', 'damp_percent': '0.00500', 'time': '1.651'}\n",
            "Quantizing self_attn.o_proj in layer 22 of 31:  69%|██████▉   | 22/32 [06:40<02:58, 17.86s/it]INFO - {'layer': 22, 'module': 'self_attn.o_proj', 'avg_loss': '0.00008', 'damp_percent': '0.00500', 'time': '1.643'}\n",
            "Quantizing mlp.up_proj in layer 22 of 31:  69%|██████▉   | 22/32 [06:42<02:58, 17.86s/it]     INFO - {'layer': 22, 'module': 'mlp.up_proj', 'avg_loss': '0.07020', 'damp_percent': '0.00500', 'time': '1.666'}\n",
            "Quantizing mlp.gate_proj in layer 22 of 31:  69%|██████▉   | 22/32 [06:44<02:58, 17.86s/it]INFO - {'layer': 22, 'module': 'mlp.gate_proj', 'avg_loss': '0.11305', 'damp_percent': '0.00500', 'time': '1.673'}\n",
            "Quantizing mlp.down_proj in layer 22 of 31:  69%|██████▉   | 22/32 [06:46<02:58, 17.86s/it]INFO - {'layer': 22, 'module': 'mlp.down_proj', 'avg_loss': '0.00063', 'damp_percent': '0.00500', 'time': '6.245'}\n",
            "Quantizing self_attn.k_proj in layer 23 of 31:  72%|███████▏  | 23/32 [06:53<02:40, 17.85s/it]INFO - {'layer': 23, 'module': 'self_attn.k_proj', 'avg_loss': '0.02611', 'damp_percent': '0.00500', 'time': '1.621'}\n",
            "Quantizing self_attn.v_proj in layer 23 of 31:  72%|███████▏  | 23/32 [06:54<02:40, 17.85s/it]INFO - {'layer': 23, 'module': 'self_attn.v_proj', 'avg_loss': '0.00631', 'damp_percent': '0.00500', 'time': '1.641'}\n",
            "Quantizing self_attn.q_proj in layer 23 of 31:  72%|███████▏  | 23/32 [06:56<02:40, 17.85s/it]INFO - {'layer': 23, 'module': 'self_attn.q_proj', 'avg_loss': '0.05167', 'damp_percent': '0.00500', 'time': '1.654'}\n",
            "Quantizing self_attn.o_proj in layer 23 of 31:  72%|███████▏  | 23/32 [06:58<02:40, 17.85s/it]INFO - {'layer': 23, 'module': 'self_attn.o_proj', 'avg_loss': '0.00010', 'damp_percent': '0.00500', 'time': '1.628'}\n",
            "Quantizing mlp.up_proj in layer 23 of 31:  72%|███████▏  | 23/32 [07:00<02:40, 17.85s/it]     INFO - {'layer': 23, 'module': 'mlp.up_proj', 'avg_loss': '0.07539', 'damp_percent': '0.00500', 'time': '1.647'}\n",
            "Quantizing mlp.gate_proj in layer 23 of 31:  72%|███████▏  | 23/32 [07:01<02:40, 17.85s/it]INFO - {'layer': 23, 'module': 'mlp.gate_proj', 'avg_loss': '0.12104', 'damp_percent': '0.00500', 'time': '1.667'}\n",
            "Quantizing mlp.down_proj in layer 23 of 31:  72%|███████▏  | 23/32 [07:04<02:40, 17.85s/it]INFO - {'layer': 23, 'module': 'mlp.down_proj', 'avg_loss': '0.00067', 'damp_percent': '0.00500', 'time': '6.251'}\n",
            "Quantizing self_attn.k_proj in layer 24 of 31:  75%|███████▌  | 24/32 [07:11<02:22, 17.84s/it]INFO - {'layer': 24, 'module': 'self_attn.k_proj', 'avg_loss': '0.02364', 'damp_percent': '0.00500', 'time': '1.606'}\n",
            "Quantizing self_attn.v_proj in layer 24 of 31:  75%|███████▌  | 24/32 [07:12<02:22, 17.84s/it]INFO - {'layer': 24, 'module': 'self_attn.v_proj', 'avg_loss': '0.00752', 'damp_percent': '0.00500', 'time': '1.611'}\n",
            "Quantizing self_attn.q_proj in layer 24 of 31:  75%|███████▌  | 24/32 [07:14<02:22, 17.84s/it]INFO - {'layer': 24, 'module': 'self_attn.q_proj', 'avg_loss': '0.04962', 'damp_percent': '0.00500', 'time': '1.652'}\n",
            "Quantizing self_attn.o_proj in layer 24 of 31:  75%|███████▌  | 24/32 [07:16<02:22, 17.84s/it]INFO - {'layer': 24, 'module': 'self_attn.o_proj', 'avg_loss': '0.00011', 'damp_percent': '0.00500', 'time': '1.634'}\n",
            "Quantizing mlp.up_proj in layer 24 of 31:  75%|███████▌  | 24/32 [07:17<02:22, 17.84s/it]     INFO - {'layer': 24, 'module': 'mlp.up_proj', 'avg_loss': '0.08004', 'damp_percent': '0.00500', 'time': '1.665'}\n",
            "Quantizing mlp.gate_proj in layer 24 of 31:  75%|███████▌  | 24/32 [07:19<02:22, 17.84s/it]INFO - {'layer': 24, 'module': 'mlp.gate_proj', 'avg_loss': '0.12830', 'damp_percent': '0.00500', 'time': '1.664'}\n",
            "Quantizing mlp.down_proj in layer 24 of 31:  75%|███████▌  | 24/32 [07:21<02:22, 17.84s/it]INFO - {'layer': 24, 'module': 'mlp.down_proj', 'avg_loss': '0.00070', 'damp_percent': '0.00500', 'time': '6.254'}\n",
            "Quantizing self_attn.k_proj in layer 25 of 31:  78%|███████▊  | 25/32 [07:28<02:04, 17.83s/it]INFO - {'layer': 25, 'module': 'self_attn.k_proj', 'avg_loss': '0.02458', 'damp_percent': '0.00500', 'time': '1.611'}\n",
            "Quantizing self_attn.v_proj in layer 25 of 31:  78%|███████▊  | 25/32 [07:30<02:04, 17.83s/it]INFO - {'layer': 25, 'module': 'self_attn.v_proj', 'avg_loss': '0.00779', 'damp_percent': '0.00500', 'time': '1.623'}\n",
            "Quantizing self_attn.q_proj in layer 25 of 31:  78%|███████▊  | 25/32 [07:32<02:04, 17.83s/it]INFO - {'layer': 25, 'module': 'self_attn.q_proj', 'avg_loss': '0.04974', 'damp_percent': '0.00500', 'time': '1.651'}\n",
            "Quantizing self_attn.o_proj in layer 25 of 31:  78%|███████▊  | 25/32 [07:33<02:04, 17.83s/it]INFO - {'layer': 25, 'module': 'self_attn.o_proj', 'avg_loss': '0.00016', 'damp_percent': '0.00500', 'time': '1.626'}\n",
            "Quantizing mlp.up_proj in layer 25 of 31:  78%|███████▊  | 25/32 [07:35<02:04, 17.83s/it]     INFO - {'layer': 25, 'module': 'mlp.up_proj', 'avg_loss': '0.08645', 'damp_percent': '0.00500', 'time': '1.692'}\n",
            "Quantizing mlp.gate_proj in layer 25 of 31:  78%|███████▊  | 25/32 [07:37<02:04, 17.83s/it]INFO - {'layer': 25, 'module': 'mlp.gate_proj', 'avg_loss': '0.13866', 'damp_percent': '0.00500', 'time': '1.683'}\n",
            "Quantizing mlp.down_proj in layer 25 of 31:  78%|███████▊  | 25/32 [07:39<02:04, 17.83s/it]INFO - {'layer': 25, 'module': 'mlp.down_proj', 'avg_loss': '0.00080', 'damp_percent': '0.00500', 'time': '6.230'}\n",
            "Quantizing self_attn.k_proj in layer 26 of 31:  81%|████████▏ | 26/32 [07:46<01:47, 17.83s/it]INFO - {'layer': 26, 'module': 'self_attn.k_proj', 'avg_loss': '0.02344', 'damp_percent': '0.00500', 'time': '1.605'}\n",
            "Quantizing self_attn.v_proj in layer 26 of 31:  81%|████████▏ | 26/32 [07:48<01:47, 17.83s/it]INFO - {'layer': 26, 'module': 'self_attn.v_proj', 'avg_loss': '0.00817', 'damp_percent': '0.00500', 'time': '1.620'}\n",
            "Quantizing self_attn.q_proj in layer 26 of 31:  81%|████████▏ | 26/32 [07:49<01:47, 17.83s/it]INFO - {'layer': 26, 'module': 'self_attn.q_proj', 'avg_loss': '0.04547', 'damp_percent': '0.00500', 'time': '1.670'}\n",
            "Quantizing self_attn.o_proj in layer 26 of 31:  81%|████████▏ | 26/32 [07:51<01:47, 17.83s/it]INFO - {'layer': 26, 'module': 'self_attn.o_proj', 'avg_loss': '0.00017', 'damp_percent': '0.00500', 'time': '1.628'}\n",
            "Quantizing mlp.up_proj in layer 26 of 31:  81%|████████▏ | 26/32 [07:53<01:47, 17.83s/it]     INFO - {'layer': 26, 'module': 'mlp.up_proj', 'avg_loss': '0.09256', 'damp_percent': '0.00500', 'time': '1.652'}\n",
            "Quantizing mlp.gate_proj in layer 26 of 31:  81%|████████▏ | 26/32 [07:55<01:47, 17.83s/it]INFO - {'layer': 26, 'module': 'mlp.gate_proj', 'avg_loss': '0.14886', 'damp_percent': '0.00500', 'time': '1.675'}\n",
            "Quantizing mlp.down_proj in layer 26 of 31:  81%|████████▏ | 26/32 [07:57<01:47, 17.83s/it]INFO - {'layer': 26, 'module': 'mlp.down_proj', 'avg_loss': '0.00091', 'damp_percent': '0.00500', 'time': '6.236'}\n",
            "Quantizing self_attn.k_proj in layer 27 of 31:  84%|████████▍ | 27/32 [08:04<01:29, 17.83s/it]INFO - {'layer': 27, 'module': 'self_attn.k_proj', 'avg_loss': '0.02482', 'damp_percent': '0.00500', 'time': '1.612'}\n",
            "Quantizing self_attn.v_proj in layer 27 of 31:  84%|████████▍ | 27/32 [08:06<01:29, 17.83s/it]INFO - {'layer': 27, 'module': 'self_attn.v_proj', 'avg_loss': '0.00965', 'damp_percent': '0.00500', 'time': '1.626'}\n",
            "Quantizing self_attn.q_proj in layer 27 of 31:  84%|████████▍ | 27/32 [08:07<01:29, 17.83s/it]INFO - {'layer': 27, 'module': 'self_attn.q_proj', 'avg_loss': '0.04852', 'damp_percent': '0.00500', 'time': '1.663'}\n",
            "Quantizing self_attn.o_proj in layer 27 of 31:  84%|████████▍ | 27/32 [08:09<01:29, 17.83s/it]INFO - {'layer': 27, 'module': 'self_attn.o_proj', 'avg_loss': '0.00026', 'damp_percent': '0.00500', 'time': '1.634'}\n",
            "Quantizing mlp.up_proj in layer 27 of 31:  84%|████████▍ | 27/32 [08:11<01:29, 17.83s/it]     INFO - {'layer': 27, 'module': 'mlp.up_proj', 'avg_loss': '0.10096', 'damp_percent': '0.00500', 'time': '1.657'}\n",
            "Quantizing mlp.gate_proj in layer 27 of 31:  84%|████████▍ | 27/32 [08:13<01:29, 17.83s/it]INFO - {'layer': 27, 'module': 'mlp.gate_proj', 'avg_loss': '0.16123', 'damp_percent': '0.00500', 'time': '1.674'}\n",
            "Quantizing mlp.down_proj in layer 27 of 31:  84%|████████▍ | 27/32 [08:15<01:29, 17.83s/it]INFO - {'layer': 27, 'module': 'mlp.down_proj', 'avg_loss': '0.00115', 'damp_percent': '0.00500', 'time': '6.241'}\n",
            "Quantizing self_attn.k_proj in layer 28 of 31:  88%|████████▊ | 28/32 [08:22<01:11, 17.83s/it]INFO - {'layer': 28, 'module': 'self_attn.k_proj', 'avg_loss': '0.02206', 'damp_percent': '0.00500', 'time': '1.614'}\n",
            "Quantizing self_attn.v_proj in layer 28 of 31:  88%|████████▊ | 28/32 [08:23<01:11, 17.83s/it]INFO - {'layer': 28, 'module': 'self_attn.v_proj', 'avg_loss': '0.01089', 'damp_percent': '0.00500', 'time': '1.626'}\n",
            "Quantizing self_attn.q_proj in layer 28 of 31:  88%|████████▊ | 28/32 [08:25<01:11, 17.83s/it]INFO - {'layer': 28, 'module': 'self_attn.q_proj', 'avg_loss': '0.04739', 'damp_percent': '0.00500', 'time': '1.670'}\n",
            "Quantizing self_attn.o_proj in layer 28 of 31:  88%|████████▊ | 28/32 [08:27<01:11, 17.83s/it]INFO - {'layer': 28, 'module': 'self_attn.o_proj', 'avg_loss': '0.00039', 'damp_percent': '0.00500', 'time': '1.620'}\n",
            "Quantizing mlp.up_proj in layer 28 of 31:  88%|████████▊ | 28/32 [08:29<01:11, 17.83s/it]     INFO - {'layer': 28, 'module': 'mlp.up_proj', 'avg_loss': '0.11278', 'damp_percent': '0.00500', 'time': '1.651'}\n",
            "Quantizing mlp.gate_proj in layer 28 of 31:  88%|████████▊ | 28/32 [08:30<01:11, 17.83s/it]INFO - {'layer': 28, 'module': 'mlp.gate_proj', 'avg_loss': '0.17125', 'damp_percent': '0.00500', 'time': '1.659'}\n",
            "Quantizing mlp.down_proj in layer 28 of 31:  88%|████████▊ | 28/32 [08:33<01:11, 17.83s/it]INFO - {'layer': 28, 'module': 'mlp.down_proj', 'avg_loss': '0.00154', 'damp_percent': '0.00500', 'time': '6.211'}\n",
            "Quantizing self_attn.k_proj in layer 29 of 31:  91%|█████████ | 29/32 [08:40<00:53, 17.81s/it]INFO - {'layer': 29, 'module': 'self_attn.k_proj', 'avg_loss': '0.02733', 'damp_percent': '0.00500', 'time': '1.606'}\n",
            "Quantizing self_attn.v_proj in layer 29 of 31:  91%|█████████ | 29/32 [08:41<00:53, 17.81s/it]INFO - {'layer': 29, 'module': 'self_attn.v_proj', 'avg_loss': '0.01282', 'damp_percent': '0.00500', 'time': '1.613'}\n",
            "Quantizing self_attn.q_proj in layer 29 of 31:  91%|█████████ | 29/32 [08:43<00:53, 17.81s/it]INFO - {'layer': 29, 'module': 'self_attn.q_proj', 'avg_loss': '0.05175', 'damp_percent': '0.00500', 'time': '1.648'}\n",
            "Quantizing self_attn.o_proj in layer 29 of 31:  91%|█████████ | 29/32 [08:45<00:53, 17.81s/it]INFO - {'layer': 29, 'module': 'self_attn.o_proj', 'avg_loss': '0.00057', 'damp_percent': '0.00500', 'time': '1.618'}\n",
            "Quantizing mlp.up_proj in layer 29 of 31:  91%|█████████ | 29/32 [08:47<00:53, 17.81s/it]     INFO - {'layer': 29, 'module': 'mlp.up_proj', 'avg_loss': '0.12045', 'damp_percent': '0.00500', 'time': '1.652'}\n",
            "Quantizing mlp.gate_proj in layer 29 of 31:  91%|█████████ | 29/32 [08:48<00:53, 17.81s/it]INFO - {'layer': 29, 'module': 'mlp.gate_proj', 'avg_loss': '0.17405', 'damp_percent': '0.00500', 'time': '1.664'}\n",
            "Quantizing mlp.down_proj in layer 29 of 31:  91%|█████████ | 29/32 [08:50<00:53, 17.81s/it]INFO - {'layer': 29, 'module': 'mlp.down_proj', 'avg_loss': '0.00224', 'damp_percent': '0.00500', 'time': '6.246'}\n",
            "Quantizing self_attn.k_proj in layer 30 of 31:  94%|█████████▍| 30/32 [08:57<00:35, 17.80s/it]INFO - {'layer': 30, 'module': 'self_attn.k_proj', 'avg_loss': '0.01650', 'damp_percent': '0.00500', 'time': '1.611'}\n",
            "Quantizing self_attn.v_proj in layer 30 of 31:  94%|█████████▍| 30/32 [08:59<00:35, 17.80s/it]INFO - {'layer': 30, 'module': 'self_attn.v_proj', 'avg_loss': '0.01472', 'damp_percent': '0.00500', 'time': '1.650'}\n",
            "Quantizing self_attn.q_proj in layer 30 of 31:  94%|█████████▍| 30/32 [09:01<00:35, 17.80s/it]INFO - {'layer': 30, 'module': 'self_attn.q_proj', 'avg_loss': '0.03854', 'damp_percent': '0.00500', 'time': '1.658'}\n",
            "Quantizing self_attn.o_proj in layer 30 of 31:  94%|█████████▍| 30/32 [09:02<00:35, 17.80s/it]INFO - {'layer': 30, 'module': 'self_attn.o_proj', 'avg_loss': '0.00076', 'damp_percent': '0.00500', 'time': '1.627'}\n",
            "Quantizing mlp.up_proj in layer 30 of 31:  94%|█████████▍| 30/32 [09:04<00:35, 17.80s/it]     INFO - {'layer': 30, 'module': 'mlp.up_proj', 'avg_loss': '0.12522', 'damp_percent': '0.00500', 'time': '1.671'}\n",
            "Quantizing mlp.gate_proj in layer 30 of 31:  94%|█████████▍| 30/32 [09:06<00:35, 17.80s/it]INFO - {'layer': 30, 'module': 'mlp.gate_proj', 'avg_loss': '0.18604', 'damp_percent': '0.00500', 'time': '1.667'}\n",
            "Quantizing mlp.down_proj in layer 30 of 31:  94%|█████████▍| 30/32 [09:08<00:35, 17.80s/it]INFO - {'layer': 30, 'module': 'mlp.down_proj', 'avg_loss': '0.00419', 'damp_percent': '0.00500', 'time': '6.293'}\n",
            "Quantizing self_attn.k_proj in layer 31 of 31:  97%|█████████▋| 31/32 [09:15<00:17, 17.83s/it]INFO - {'layer': 31, 'module': 'self_attn.k_proj', 'avg_loss': '0.01680', 'damp_percent': '0.00500', 'time': '1.608'}\n",
            "Quantizing self_attn.v_proj in layer 31 of 31:  97%|█████████▋| 31/32 [09:17<00:17, 17.83s/it]INFO - {'layer': 31, 'module': 'self_attn.v_proj', 'avg_loss': '0.00901', 'damp_percent': '0.00500', 'time': '1.614'}\n",
            "Quantizing self_attn.q_proj in layer 31 of 31:  97%|█████████▋| 31/32 [09:19<00:17, 17.83s/it]INFO - {'layer': 31, 'module': 'self_attn.q_proj', 'avg_loss': '0.03791', 'damp_percent': '0.00500', 'time': '1.646'}\n",
            "Quantizing self_attn.o_proj in layer 31 of 31:  97%|█████████▋| 31/32 [09:20<00:17, 17.83s/it]INFO - {'layer': 31, 'module': 'self_attn.o_proj', 'avg_loss': '0.00333', 'damp_percent': '0.00500', 'time': '1.627'}\n",
            "Quantizing mlp.up_proj in layer 31 of 31:  97%|█████████▋| 31/32 [09:22<00:17, 17.83s/it]     INFO - {'layer': 31, 'module': 'mlp.up_proj', 'avg_loss': '0.11848', 'damp_percent': '0.00500', 'time': '1.680'}\n",
            "Quantizing mlp.gate_proj in layer 31 of 31:  97%|█████████▋| 31/32 [09:24<00:17, 17.83s/it]INFO - {'layer': 31, 'module': 'mlp.gate_proj', 'avg_loss': '0.17089', 'damp_percent': '0.00500', 'time': '1.672'}\n",
            "Quantizing mlp.down_proj in layer 31 of 31:  97%|█████████▋| 31/32 [09:26<00:17, 17.83s/it]INFO - {'layer': 31, 'module': 'mlp.down_proj', 'avg_loss': '0.06427', 'damp_percent': '0.00500', 'time': '6.230'}\n",
            "Quantizing mlp.down_proj in layer 31 of 31: 100%|██████████| 32/32 [09:33<00:00, 17.92s/it]\n",
            "INFO - Quantization summary:\n",
            "[{'layer': 0, 'module': 'self_attn.k_proj', 'avg_loss': '0.00119', 'damp_percent': '0.00500', 'time': '3.234'}, {'layer': 0, 'module': 'self_attn.v_proj', 'avg_loss': '0.00005', 'damp_percent': '0.00500', 'time': '1.608'}, {'layer': 0, 'module': 'self_attn.q_proj', 'avg_loss': '0.00199', 'damp_percent': '0.00500', 'time': '1.643'}, {'layer': 0, 'module': 'self_attn.o_proj', 'avg_loss': '0.00000', 'damp_percent': '0.00500', 'time': '1.620'}, {'layer': 0, 'module': 'mlp.up_proj', 'avg_loss': '0.00368', 'damp_percent': '0.00500', 'time': '1.645'}, {'layer': 0, 'module': 'mlp.gate_proj', 'avg_loss': '0.00435', 'damp_percent': '0.00500', 'time': '1.649'}, {'layer': 0, 'module': 'mlp.down_proj', 'avg_loss': '0.00005', 'damp_percent': '0.00500', 'time': '6.314'}, {'layer': 1, 'module': 'self_attn.k_proj', 'avg_loss': '0.00238', 'damp_percent': '0.00500', 'time': '1.603'}, {'layer': 1, 'module': 'self_attn.v_proj', 'avg_loss': '0.00019', 'damp_percent': '0.00500', 'time': '1.615'}, {'layer': 1, 'module': 'self_attn.q_proj', 'avg_loss': '0.00471', 'damp_percent': '0.00500', 'time': '1.652'}, {'layer': 1, 'module': 'self_attn.o_proj', 'avg_loss': '0.00001', 'damp_percent': '0.00500', 'time': '1.695'}, {'layer': 1, 'module': 'mlp.up_proj', 'avg_loss': '0.00831', 'damp_percent': '0.00500', 'time': '1.646'}, {'layer': 1, 'module': 'mlp.gate_proj', 'avg_loss': '0.00979', 'damp_percent': '0.00500', 'time': '1.669'}, {'layer': 1, 'module': 'mlp.down_proj', 'avg_loss': '0.84043', 'damp_percent': '0.00500', 'time': '6.209'}, {'layer': 2, 'module': 'self_attn.k_proj', 'avg_loss': '0.01027', 'damp_percent': '0.00500', 'time': '1.614'}, {'layer': 2, 'module': 'self_attn.v_proj', 'avg_loss': '0.00078', 'damp_percent': '0.00500', 'time': '1.643'}, {'layer': 2, 'module': 'self_attn.q_proj', 'avg_loss': '0.01926', 'damp_percent': '0.00500', 'time': '1.697'}, {'layer': 2, 'module': 'self_attn.o_proj', 'avg_loss': '0.00001', 'damp_percent': '0.00500', 'time': '1.641'}, {'layer': 2, 'module': 'mlp.up_proj', 'avg_loss': '0.01392', 'damp_percent': '0.00500', 'time': '1.650'}, {'layer': 2, 'module': 'mlp.gate_proj', 'avg_loss': '0.01725', 'damp_percent': '0.00500', 'time': '1.678'}, {'layer': 2, 'module': 'mlp.down_proj', 'avg_loss': '0.00002', 'damp_percent': '0.00500', 'time': '6.252'}, {'layer': 3, 'module': 'self_attn.k_proj', 'avg_loss': '0.01386', 'damp_percent': '0.00500', 'time': '1.613'}, {'layer': 3, 'module': 'self_attn.v_proj', 'avg_loss': '0.00147', 'damp_percent': '0.00500', 'time': '1.628'}, {'layer': 3, 'module': 'self_attn.q_proj', 'avg_loss': '0.02667', 'damp_percent': '0.00500', 'time': '1.649'}, {'layer': 3, 'module': 'self_attn.o_proj', 'avg_loss': '0.00002', 'damp_percent': '0.00500', 'time': '1.645'}, {'layer': 3, 'module': 'mlp.up_proj', 'avg_loss': '0.01933', 'damp_percent': '0.00500', 'time': '1.658'}, {'layer': 3, 'module': 'mlp.gate_proj', 'avg_loss': '0.02750', 'damp_percent': '0.00500', 'time': '1.672'}, {'layer': 3, 'module': 'mlp.down_proj', 'avg_loss': '0.00004', 'damp_percent': '0.00500', 'time': '6.234'}, {'layer': 4, 'module': 'self_attn.k_proj', 'avg_loss': '0.01120', 'damp_percent': '0.00500', 'time': '1.604'}, {'layer': 4, 'module': 'self_attn.v_proj', 'avg_loss': '0.00146', 'damp_percent': '0.00500', 'time': '1.640'}, {'layer': 4, 'module': 'self_attn.q_proj', 'avg_loss': '0.02152', 'damp_percent': '0.00500', 'time': '1.658'}, {'layer': 4, 'module': 'self_attn.o_proj', 'avg_loss': '0.00003', 'damp_percent': '0.00500', 'time': '1.617'}, {'layer': 4, 'module': 'mlp.up_proj', 'avg_loss': '0.02430', 'damp_percent': '0.00500', 'time': '1.647'}, {'layer': 4, 'module': 'mlp.gate_proj', 'avg_loss': '0.03881', 'damp_percent': '0.00500', 'time': '1.668'}, {'layer': 4, 'module': 'mlp.down_proj', 'avg_loss': '0.00007', 'damp_percent': '0.00500', 'time': '6.310'}, {'layer': 5, 'module': 'self_attn.k_proj', 'avg_loss': '0.01470', 'damp_percent': '0.00500', 'time': '1.606'}, {'layer': 5, 'module': 'self_attn.v_proj', 'avg_loss': '0.00134', 'damp_percent': '0.00500', 'time': '1.625'}, {'layer': 5, 'module': 'self_attn.q_proj', 'avg_loss': '0.02803', 'damp_percent': '0.00500', 'time': '1.647'}, {'layer': 5, 'module': 'self_attn.o_proj', 'avg_loss': '0.00003', 'damp_percent': '0.00500', 'time': '1.621'}, {'layer': 5, 'module': 'mlp.up_proj', 'avg_loss': '0.02872', 'damp_percent': '0.00500', 'time': '1.651'}, {'layer': 5, 'module': 'mlp.gate_proj', 'avg_loss': '0.04535', 'damp_percent': '0.00500', 'time': '1.660'}, {'layer': 5, 'module': 'mlp.down_proj', 'avg_loss': '0.00010', 'damp_percent': '0.00500', 'time': '6.214'}, {'layer': 6, 'module': 'self_attn.k_proj', 'avg_loss': '0.01468', 'damp_percent': '0.00500', 'time': '1.601'}, {'layer': 6, 'module': 'self_attn.v_proj', 'avg_loss': '0.00162', 'damp_percent': '0.00500', 'time': '1.629'}, {'layer': 6, 'module': 'self_attn.q_proj', 'avg_loss': '0.02949', 'damp_percent': '0.00500', 'time': '1.647'}, {'layer': 6, 'module': 'self_attn.o_proj', 'avg_loss': '0.00006', 'damp_percent': '0.00500', 'time': '1.634'}, {'layer': 6, 'module': 'mlp.up_proj', 'avg_loss': '0.03058', 'damp_percent': '0.00500', 'time': '1.655'}, {'layer': 6, 'module': 'mlp.gate_proj', 'avg_loss': '0.04875', 'damp_percent': '0.00500', 'time': '1.663'}, {'layer': 6, 'module': 'mlp.down_proj', 'avg_loss': '0.00013', 'damp_percent': '0.00500', 'time': '6.217'}, {'layer': 7, 'module': 'self_attn.k_proj', 'avg_loss': '0.01619', 'damp_percent': '0.00500', 'time': '1.601'}, {'layer': 7, 'module': 'self_attn.v_proj', 'avg_loss': '0.00164', 'damp_percent': '0.00500', 'time': '1.613'}, {'layer': 7, 'module': 'self_attn.q_proj', 'avg_loss': '0.02940', 'damp_percent': '0.00500', 'time': '1.649'}, {'layer': 7, 'module': 'self_attn.o_proj', 'avg_loss': '0.00010', 'damp_percent': '0.00500', 'time': '1.632'}, {'layer': 7, 'module': 'mlp.up_proj', 'avg_loss': '0.03146', 'damp_percent': '0.00500', 'time': '1.669'}, {'layer': 7, 'module': 'mlp.gate_proj', 'avg_loss': '0.04726', 'damp_percent': '0.00500', 'time': '1.675'}, {'layer': 7, 'module': 'mlp.down_proj', 'avg_loss': '0.00016', 'damp_percent': '0.00500', 'time': '6.232'}, {'layer': 8, 'module': 'self_attn.k_proj', 'avg_loss': '0.01793', 'damp_percent': '0.00500', 'time': '1.607'}, {'layer': 8, 'module': 'self_attn.v_proj', 'avg_loss': '0.00210', 'damp_percent': '0.00500', 'time': '1.622'}, {'layer': 8, 'module': 'self_attn.q_proj', 'avg_loss': '0.03302', 'damp_percent': '0.00500', 'time': '1.676'}, {'layer': 8, 'module': 'self_attn.o_proj', 'avg_loss': '0.00012', 'damp_percent': '0.00500', 'time': '1.622'}, {'layer': 8, 'module': 'mlp.up_proj', 'avg_loss': '0.03190', 'damp_percent': '0.00500', 'time': '1.643'}, {'layer': 8, 'module': 'mlp.gate_proj', 'avg_loss': '0.04822', 'damp_percent': '0.00500', 'time': '1.664'}, {'layer': 8, 'module': 'mlp.down_proj', 'avg_loss': '0.00015', 'damp_percent': '0.00500', 'time': '6.257'}, {'layer': 9, 'module': 'self_attn.k_proj', 'avg_loss': '0.01798', 'damp_percent': '0.00500', 'time': '1.608'}, {'layer': 9, 'module': 'self_attn.v_proj', 'avg_loss': '0.00277', 'damp_percent': '0.00500', 'time': '1.603'}, {'layer': 9, 'module': 'self_attn.q_proj', 'avg_loss': '0.03262', 'damp_percent': '0.00500', 'time': '1.657'}, {'layer': 9, 'module': 'self_attn.o_proj', 'avg_loss': '0.00014', 'damp_percent': '0.00500', 'time': '1.647'}, {'layer': 9, 'module': 'mlp.up_proj', 'avg_loss': '0.03147', 'damp_percent': '0.00500', 'time': '1.667'}, {'layer': 9, 'module': 'mlp.gate_proj', 'avg_loss': '0.04817', 'damp_percent': '0.00500', 'time': '1.678'}, {'layer': 9, 'module': 'mlp.down_proj', 'avg_loss': '0.00015', 'damp_percent': '0.00500', 'time': '6.253'}, {'layer': 10, 'module': 'self_attn.k_proj', 'avg_loss': '0.01924', 'damp_percent': '0.00500', 'time': '1.620'}, {'layer': 10, 'module': 'self_attn.v_proj', 'avg_loss': '0.00217', 'damp_percent': '0.00500', 'time': '1.624'}, {'layer': 10, 'module': 'self_attn.q_proj', 'avg_loss': '0.03551', 'damp_percent': '0.00500', 'time': '1.660'}, {'layer': 10, 'module': 'self_attn.o_proj', 'avg_loss': '0.00012', 'damp_percent': '0.00500', 'time': '1.624'}, {'layer': 10, 'module': 'mlp.up_proj', 'avg_loss': '0.03116', 'damp_percent': '0.00500', 'time': '1.651'}, {'layer': 10, 'module': 'mlp.gate_proj', 'avg_loss': '0.04442', 'damp_percent': '0.00500', 'time': '1.675'}, {'layer': 10, 'module': 'mlp.down_proj', 'avg_loss': '0.00017', 'damp_percent': '0.00500', 'time': '6.284'}, {'layer': 11, 'module': 'self_attn.k_proj', 'avg_loss': '0.01967', 'damp_percent': '0.00500', 'time': '1.605'}, {'layer': 11, 'module': 'self_attn.v_proj', 'avg_loss': '0.00211', 'damp_percent': '0.00500', 'time': '1.615'}, {'layer': 11, 'module': 'self_attn.q_proj', 'avg_loss': '0.03333', 'damp_percent': '0.00500', 'time': '1.648'}, {'layer': 11, 'module': 'self_attn.o_proj', 'avg_loss': '0.00015', 'damp_percent': '0.00500', 'time': '1.649'}, {'layer': 11, 'module': 'mlp.up_proj', 'avg_loss': '0.03168', 'damp_percent': '0.00500', 'time': '1.662'}, {'layer': 11, 'module': 'mlp.gate_proj', 'avg_loss': '0.04335', 'damp_percent': '0.00500', 'time': '1.662'}, {'layer': 11, 'module': 'mlp.down_proj', 'avg_loss': '0.00016', 'damp_percent': '0.00500', 'time': '6.254'}, {'layer': 12, 'module': 'self_attn.k_proj', 'avg_loss': '0.01659', 'damp_percent': '0.00500', 'time': '1.610'}, {'layer': 12, 'module': 'self_attn.v_proj', 'avg_loss': '0.00256', 'damp_percent': '0.00500', 'time': '1.615'}, {'layer': 12, 'module': 'self_attn.q_proj', 'avg_loss': '0.03003', 'damp_percent': '0.00500', 'time': '1.650'}, {'layer': 12, 'module': 'self_attn.o_proj', 'avg_loss': '0.00018', 'damp_percent': '0.00500', 'time': '1.646'}, {'layer': 12, 'module': 'mlp.up_proj', 'avg_loss': '0.03084', 'damp_percent': '0.00500', 'time': '1.686'}, {'layer': 12, 'module': 'mlp.gate_proj', 'avg_loss': '0.03949', 'damp_percent': '0.00500', 'time': '1.674'}, {'layer': 12, 'module': 'mlp.down_proj', 'avg_loss': '0.00017', 'damp_percent': '0.00500', 'time': '6.289'}, {'layer': 13, 'module': 'self_attn.k_proj', 'avg_loss': '0.02102', 'damp_percent': '0.00500', 'time': '1.626'}, {'layer': 13, 'module': 'self_attn.v_proj', 'avg_loss': '0.00273', 'damp_percent': '0.00500', 'time': '1.644'}, {'layer': 13, 'module': 'self_attn.q_proj', 'avg_loss': '0.03727', 'damp_percent': '0.00500', 'time': '1.675'}, {'layer': 13, 'module': 'self_attn.o_proj', 'avg_loss': '0.00015', 'damp_percent': '0.00500', 'time': '1.643'}, {'layer': 13, 'module': 'mlp.up_proj', 'avg_loss': '0.03224', 'damp_percent': '0.00500', 'time': '1.673'}, {'layer': 13, 'module': 'mlp.gate_proj', 'avg_loss': '0.04095', 'damp_percent': '0.00500', 'time': '1.690'}, {'layer': 13, 'module': 'mlp.down_proj', 'avg_loss': '0.00019', 'damp_percent': '0.00500', 'time': '6.347'}, {'layer': 14, 'module': 'self_attn.k_proj', 'avg_loss': '0.02097', 'damp_percent': '0.00500', 'time': '1.633'}, {'layer': 14, 'module': 'self_attn.v_proj', 'avg_loss': '0.00269', 'damp_percent': '0.00500', 'time': '1.623'}, {'layer': 14, 'module': 'self_attn.q_proj', 'avg_loss': '0.03636', 'damp_percent': '0.00500', 'time': '1.670'}, {'layer': 14, 'module': 'self_attn.o_proj', 'avg_loss': '0.00018', 'damp_percent': '0.00500', 'time': '1.644'}, {'layer': 14, 'module': 'mlp.up_proj', 'avg_loss': '0.03487', 'damp_percent': '0.00500', 'time': '1.653'}, {'layer': 14, 'module': 'mlp.gate_proj', 'avg_loss': '0.04589', 'damp_percent': '0.00500', 'time': '1.701'}, {'layer': 14, 'module': 'mlp.down_proj', 'avg_loss': '0.00024', 'damp_percent': '0.00500', 'time': '6.262'}, {'layer': 15, 'module': 'self_attn.k_proj', 'avg_loss': '0.02006', 'damp_percent': '0.00500', 'time': '1.601'}, {'layer': 15, 'module': 'self_attn.v_proj', 'avg_loss': '0.00311', 'damp_percent': '0.00500', 'time': '1.697'}, {'layer': 15, 'module': 'self_attn.q_proj', 'avg_loss': '0.04323', 'damp_percent': '0.00500', 'time': '1.673'}, {'layer': 15, 'module': 'self_attn.o_proj', 'avg_loss': '0.00018', 'damp_percent': '0.00500', 'time': '1.634'}, {'layer': 15, 'module': 'mlp.up_proj', 'avg_loss': '0.03869', 'damp_percent': '0.00500', 'time': '1.662'}, {'layer': 15, 'module': 'mlp.gate_proj', 'avg_loss': '0.05388', 'damp_percent': '0.00500', 'time': '1.667'}, {'layer': 15, 'module': 'mlp.down_proj', 'avg_loss': '0.00030', 'damp_percent': '0.00500', 'time': '6.266'}, {'layer': 16, 'module': 'self_attn.k_proj', 'avg_loss': '0.02000', 'damp_percent': '0.00500', 'time': '1.615'}, {'layer': 16, 'module': 'self_attn.v_proj', 'avg_loss': '0.00263', 'damp_percent': '0.00500', 'time': '1.623'}, {'layer': 16, 'module': 'self_attn.q_proj', 'avg_loss': '0.03986', 'damp_percent': '0.00500', 'time': '1.666'}, {'layer': 16, 'module': 'self_attn.o_proj', 'avg_loss': '0.00018', 'damp_percent': '0.00500', 'time': '1.630'}, {'layer': 16, 'module': 'mlp.up_proj', 'avg_loss': '0.04260', 'damp_percent': '0.00500', 'time': '1.683'}, {'layer': 16, 'module': 'mlp.gate_proj', 'avg_loss': '0.06429', 'damp_percent': '0.00500', 'time': '1.694'}, {'layer': 16, 'module': 'mlp.down_proj', 'avg_loss': '0.00035', 'damp_percent': '0.00500', 'time': '6.264'}, {'layer': 17, 'module': 'self_attn.k_proj', 'avg_loss': '0.02126', 'damp_percent': '0.00500', 'time': '1.604'}, {'layer': 17, 'module': 'self_attn.v_proj', 'avg_loss': '0.00350', 'damp_percent': '0.00500', 'time': '1.638'}, {'layer': 17, 'module': 'self_attn.q_proj', 'avg_loss': '0.04381', 'damp_percent': '0.00500', 'time': '1.663'}, {'layer': 17, 'module': 'self_attn.o_proj', 'avg_loss': '0.00012', 'damp_percent': '0.00500', 'time': '1.638'}, {'layer': 17, 'module': 'mlp.up_proj', 'avg_loss': '0.04671', 'damp_percent': '0.00500', 'time': '1.655'}, {'layer': 17, 'module': 'mlp.gate_proj', 'avg_loss': '0.07192', 'damp_percent': '0.00500', 'time': '1.666'}, {'layer': 17, 'module': 'mlp.down_proj', 'avg_loss': '0.00042', 'damp_percent': '0.00500', 'time': '6.274'}, {'layer': 18, 'module': 'self_attn.k_proj', 'avg_loss': '0.02425', 'damp_percent': '0.00500', 'time': '1.604'}, {'layer': 18, 'module': 'self_attn.v_proj', 'avg_loss': '0.00311', 'damp_percent': '0.00500', 'time': '1.616'}, {'layer': 18, 'module': 'self_attn.q_proj', 'avg_loss': '0.04720', 'damp_percent': '0.00500', 'time': '1.656'}, {'layer': 18, 'module': 'self_attn.o_proj', 'avg_loss': '0.00009', 'damp_percent': '0.00500', 'time': '1.627'}, {'layer': 18, 'module': 'mlp.up_proj', 'avg_loss': '0.05035', 'damp_percent': '0.00500', 'time': '1.667'}, {'layer': 18, 'module': 'mlp.gate_proj', 'avg_loss': '0.07981', 'damp_percent': '0.00500', 'time': '1.741'}, {'layer': 18, 'module': 'mlp.down_proj', 'avg_loss': '0.00044', 'damp_percent': '0.00500', 'time': '6.248'}, {'layer': 19, 'module': 'self_attn.k_proj', 'avg_loss': '0.02354', 'damp_percent': '0.00500', 'time': '1.620'}, {'layer': 19, 'module': 'self_attn.v_proj', 'avg_loss': '0.00364', 'damp_percent': '0.00500', 'time': '1.623'}, {'layer': 19, 'module': 'self_attn.q_proj', 'avg_loss': '0.04848', 'damp_percent': '0.00500', 'time': '1.647'}, {'layer': 19, 'module': 'self_attn.o_proj', 'avg_loss': '0.00007', 'damp_percent': '0.00500', 'time': '1.640'}, {'layer': 19, 'module': 'mlp.up_proj', 'avg_loss': '0.05403', 'damp_percent': '0.00500', 'time': '1.648'}, {'layer': 19, 'module': 'mlp.gate_proj', 'avg_loss': '0.08745', 'damp_percent': '0.00500', 'time': '1.663'}, {'layer': 19, 'module': 'mlp.down_proj', 'avg_loss': '0.00048', 'damp_percent': '0.00500', 'time': '6.256'}, {'layer': 20, 'module': 'self_attn.k_proj', 'avg_loss': '0.02356', 'damp_percent': '0.00500', 'time': '1.597'}, {'layer': 20, 'module': 'self_attn.v_proj', 'avg_loss': '0.00422', 'damp_percent': '0.00500', 'time': '1.600'}, {'layer': 20, 'module': 'self_attn.q_proj', 'avg_loss': '0.04948', 'damp_percent': '0.00500', 'time': '1.629'}, {'layer': 20, 'module': 'self_attn.o_proj', 'avg_loss': '0.00009', 'damp_percent': '0.00500', 'time': '1.624'}, {'layer': 20, 'module': 'mlp.up_proj', 'avg_loss': '0.05972', 'damp_percent': '0.00500', 'time': '1.661'}, {'layer': 20, 'module': 'mlp.gate_proj', 'avg_loss': '0.09566', 'damp_percent': '0.00500', 'time': '1.681'}, {'layer': 20, 'module': 'mlp.down_proj', 'avg_loss': '0.00052', 'damp_percent': '0.00500', 'time': '6.237'}, {'layer': 21, 'module': 'self_attn.k_proj', 'avg_loss': '0.02444', 'damp_percent': '0.00500', 'time': '1.627'}, {'layer': 21, 'module': 'self_attn.v_proj', 'avg_loss': '0.00458', 'damp_percent': '0.00500', 'time': '1.623'}, {'layer': 21, 'module': 'self_attn.q_proj', 'avg_loss': '0.04822', 'damp_percent': '0.00500', 'time': '1.659'}, {'layer': 21, 'module': 'self_attn.o_proj', 'avg_loss': '0.00013', 'damp_percent': '0.00500', 'time': '1.629'}, {'layer': 21, 'module': 'mlp.up_proj', 'avg_loss': '0.06599', 'damp_percent': '0.00500', 'time': '1.650'}, {'layer': 21, 'module': 'mlp.gate_proj', 'avg_loss': '0.10653', 'damp_percent': '0.00500', 'time': '1.670'}, {'layer': 21, 'module': 'mlp.down_proj', 'avg_loss': '0.00060', 'damp_percent': '0.00500', 'time': '6.253'}, {'layer': 22, 'module': 'self_attn.k_proj', 'avg_loss': '0.02509', 'damp_percent': '0.00500', 'time': '1.609'}, {'layer': 22, 'module': 'self_attn.v_proj', 'avg_loss': '0.00537', 'damp_percent': '0.00500', 'time': '1.616'}, {'layer': 22, 'module': 'self_attn.q_proj', 'avg_loss': '0.04935', 'damp_percent': '0.00500', 'time': '1.651'}, {'layer': 22, 'module': 'self_attn.o_proj', 'avg_loss': '0.00008', 'damp_percent': '0.00500', 'time': '1.643'}, {'layer': 22, 'module': 'mlp.up_proj', 'avg_loss': '0.07020', 'damp_percent': '0.00500', 'time': '1.666'}, {'layer': 22, 'module': 'mlp.gate_proj', 'avg_loss': '0.11305', 'damp_percent': '0.00500', 'time': '1.673'}, {'layer': 22, 'module': 'mlp.down_proj', 'avg_loss': '0.00063', 'damp_percent': '0.00500', 'time': '6.245'}, {'layer': 23, 'module': 'self_attn.k_proj', 'avg_loss': '0.02611', 'damp_percent': '0.00500', 'time': '1.621'}, {'layer': 23, 'module': 'self_attn.v_proj', 'avg_loss': '0.00631', 'damp_percent': '0.00500', 'time': '1.641'}, {'layer': 23, 'module': 'self_attn.q_proj', 'avg_loss': '0.05167', 'damp_percent': '0.00500', 'time': '1.654'}, {'layer': 23, 'module': 'self_attn.o_proj', 'avg_loss': '0.00010', 'damp_percent': '0.00500', 'time': '1.628'}, {'layer': 23, 'module': 'mlp.up_proj', 'avg_loss': '0.07539', 'damp_percent': '0.00500', 'time': '1.647'}, {'layer': 23, 'module': 'mlp.gate_proj', 'avg_loss': '0.12104', 'damp_percent': '0.00500', 'time': '1.667'}, {'layer': 23, 'module': 'mlp.down_proj', 'avg_loss': '0.00067', 'damp_percent': '0.00500', 'time': '6.251'}, {'layer': 24, 'module': 'self_attn.k_proj', 'avg_loss': '0.02364', 'damp_percent': '0.00500', 'time': '1.606'}, {'layer': 24, 'module': 'self_attn.v_proj', 'avg_loss': '0.00752', 'damp_percent': '0.00500', 'time': '1.611'}, {'layer': 24, 'module': 'self_attn.q_proj', 'avg_loss': '0.04962', 'damp_percent': '0.00500', 'time': '1.652'}, {'layer': 24, 'module': 'self_attn.o_proj', 'avg_loss': '0.00011', 'damp_percent': '0.00500', 'time': '1.634'}, {'layer': 24, 'module': 'mlp.up_proj', 'avg_loss': '0.08004', 'damp_percent': '0.00500', 'time': '1.665'}, {'layer': 24, 'module': 'mlp.gate_proj', 'avg_loss': '0.12830', 'damp_percent': '0.00500', 'time': '1.664'}, {'layer': 24, 'module': 'mlp.down_proj', 'avg_loss': '0.00070', 'damp_percent': '0.00500', 'time': '6.254'}, {'layer': 25, 'module': 'self_attn.k_proj', 'avg_loss': '0.02458', 'damp_percent': '0.00500', 'time': '1.611'}, {'layer': 25, 'module': 'self_attn.v_proj', 'avg_loss': '0.00779', 'damp_percent': '0.00500', 'time': '1.623'}, {'layer': 25, 'module': 'self_attn.q_proj', 'avg_loss': '0.04974', 'damp_percent': '0.00500', 'time': '1.651'}, {'layer': 25, 'module': 'self_attn.o_proj', 'avg_loss': '0.00016', 'damp_percent': '0.00500', 'time': '1.626'}, {'layer': 25, 'module': 'mlp.up_proj', 'avg_loss': '0.08645', 'damp_percent': '0.00500', 'time': '1.692'}, {'layer': 25, 'module': 'mlp.gate_proj', 'avg_loss': '0.13866', 'damp_percent': '0.00500', 'time': '1.683'}, {'layer': 25, 'module': 'mlp.down_proj', 'avg_loss': '0.00080', 'damp_percent': '0.00500', 'time': '6.230'}, {'layer': 26, 'module': 'self_attn.k_proj', 'avg_loss': '0.02344', 'damp_percent': '0.00500', 'time': '1.605'}, {'layer': 26, 'module': 'self_attn.v_proj', 'avg_loss': '0.00817', 'damp_percent': '0.00500', 'time': '1.620'}, {'layer': 26, 'module': 'self_attn.q_proj', 'avg_loss': '0.04547', 'damp_percent': '0.00500', 'time': '1.670'}, {'layer': 26, 'module': 'self_attn.o_proj', 'avg_loss': '0.00017', 'damp_percent': '0.00500', 'time': '1.628'}, {'layer': 26, 'module': 'mlp.up_proj', 'avg_loss': '0.09256', 'damp_percent': '0.00500', 'time': '1.652'}, {'layer': 26, 'module': 'mlp.gate_proj', 'avg_loss': '0.14886', 'damp_percent': '0.00500', 'time': '1.675'}, {'layer': 26, 'module': 'mlp.down_proj', 'avg_loss': '0.00091', 'damp_percent': '0.00500', 'time': '6.236'}, {'layer': 27, 'module': 'self_attn.k_proj', 'avg_loss': '0.02482', 'damp_percent': '0.00500', 'time': '1.612'}, {'layer': 27, 'module': 'self_attn.v_proj', 'avg_loss': '0.00965', 'damp_percent': '0.00500', 'time': '1.626'}, {'layer': 27, 'module': 'self_attn.q_proj', 'avg_loss': '0.04852', 'damp_percent': '0.00500', 'time': '1.663'}, {'layer': 27, 'module': 'self_attn.o_proj', 'avg_loss': '0.00026', 'damp_percent': '0.00500', 'time': '1.634'}, {'layer': 27, 'module': 'mlp.up_proj', 'avg_loss': '0.10096', 'damp_percent': '0.00500', 'time': '1.657'}, {'layer': 27, 'module': 'mlp.gate_proj', 'avg_loss': '0.16123', 'damp_percent': '0.00500', 'time': '1.674'}, {'layer': 27, 'module': 'mlp.down_proj', 'avg_loss': '0.00115', 'damp_percent': '0.00500', 'time': '6.241'}, {'layer': 28, 'module': 'self_attn.k_proj', 'avg_loss': '0.02206', 'damp_percent': '0.00500', 'time': '1.614'}, {'layer': 28, 'module': 'self_attn.v_proj', 'avg_loss': '0.01089', 'damp_percent': '0.00500', 'time': '1.626'}, {'layer': 28, 'module': 'self_attn.q_proj', 'avg_loss': '0.04739', 'damp_percent': '0.00500', 'time': '1.670'}, {'layer': 28, 'module': 'self_attn.o_proj', 'avg_loss': '0.00039', 'damp_percent': '0.00500', 'time': '1.620'}, {'layer': 28, 'module': 'mlp.up_proj', 'avg_loss': '0.11278', 'damp_percent': '0.00500', 'time': '1.651'}, {'layer': 28, 'module': 'mlp.gate_proj', 'avg_loss': '0.17125', 'damp_percent': '0.00500', 'time': '1.659'}, {'layer': 28, 'module': 'mlp.down_proj', 'avg_loss': '0.00154', 'damp_percent': '0.00500', 'time': '6.211'}, {'layer': 29, 'module': 'self_attn.k_proj', 'avg_loss': '0.02733', 'damp_percent': '0.00500', 'time': '1.606'}, {'layer': 29, 'module': 'self_attn.v_proj', 'avg_loss': '0.01282', 'damp_percent': '0.00500', 'time': '1.613'}, {'layer': 29, 'module': 'self_attn.q_proj', 'avg_loss': '0.05175', 'damp_percent': '0.00500', 'time': '1.648'}, {'layer': 29, 'module': 'self_attn.o_proj', 'avg_loss': '0.00057', 'damp_percent': '0.00500', 'time': '1.618'}, {'layer': 29, 'module': 'mlp.up_proj', 'avg_loss': '0.12045', 'damp_percent': '0.00500', 'time': '1.652'}, {'layer': 29, 'module': 'mlp.gate_proj', 'avg_loss': '0.17405', 'damp_percent': '0.00500', 'time': '1.664'}, {'layer': 29, 'module': 'mlp.down_proj', 'avg_loss': '0.00224', 'damp_percent': '0.00500', 'time': '6.246'}, {'layer': 30, 'module': 'self_attn.k_proj', 'avg_loss': '0.01650', 'damp_percent': '0.00500', 'time': '1.611'}, {'layer': 30, 'module': 'self_attn.v_proj', 'avg_loss': '0.01472', 'damp_percent': '0.00500', 'time': '1.650'}, {'layer': 30, 'module': 'self_attn.q_proj', 'avg_loss': '0.03854', 'damp_percent': '0.00500', 'time': '1.658'}, {'layer': 30, 'module': 'self_attn.o_proj', 'avg_loss': '0.00076', 'damp_percent': '0.00500', 'time': '1.627'}, {'layer': 30, 'module': 'mlp.up_proj', 'avg_loss': '0.12522', 'damp_percent': '0.00500', 'time': '1.671'}, {'layer': 30, 'module': 'mlp.gate_proj', 'avg_loss': '0.18604', 'damp_percent': '0.00500', 'time': '1.667'}, {'layer': 30, 'module': 'mlp.down_proj', 'avg_loss': '0.00419', 'damp_percent': '0.00500', 'time': '6.293'}, {'layer': 31, 'module': 'self_attn.k_proj', 'avg_loss': '0.01680', 'damp_percent': '0.00500', 'time': '1.608'}, {'layer': 31, 'module': 'self_attn.v_proj', 'avg_loss': '0.00901', 'damp_percent': '0.00500', 'time': '1.614'}, {'layer': 31, 'module': 'self_attn.q_proj', 'avg_loss': '0.03791', 'damp_percent': '0.00500', 'time': '1.646'}, {'layer': 31, 'module': 'self_attn.o_proj', 'avg_loss': '0.00333', 'damp_percent': '0.00500', 'time': '1.627'}, {'layer': 31, 'module': 'mlp.up_proj', 'avg_loss': '0.11848', 'damp_percent': '0.00500', 'time': '1.680'}, {'layer': 31, 'module': 'mlp.gate_proj', 'avg_loss': '0.17089', 'damp_percent': '0.00500', 'time': '1.672'}, {'layer': 31, 'module': 'mlp.down_proj', 'avg_loss': '0.06427', 'damp_percent': '0.00500', 'time': '6.230'}]\n",
            "INFO - {'layer': 0, 'module': 'self_attn.k_proj', 'avg_loss': '0.00119', 'damp_percent': '0.00500', 'time': '3.234'}\n",
            "INFO - {'layer': 0, 'module': 'self_attn.v_proj', 'avg_loss': '0.00005', 'damp_percent': '0.00500', 'time': '1.608'}\n",
            "INFO - {'layer': 0, 'module': 'self_attn.q_proj', 'avg_loss': '0.00199', 'damp_percent': '0.00500', 'time': '1.643'}\n",
            "INFO - {'layer': 0, 'module': 'self_attn.o_proj', 'avg_loss': '0.00000', 'damp_percent': '0.00500', 'time': '1.620'}\n",
            "INFO - {'layer': 0, 'module': 'mlp.up_proj', 'avg_loss': '0.00368', 'damp_percent': '0.00500', 'time': '1.645'}\n",
            "INFO - {'layer': 0, 'module': 'mlp.gate_proj', 'avg_loss': '0.00435', 'damp_percent': '0.00500', 'time': '1.649'}\n",
            "INFO - {'layer': 0, 'module': 'mlp.down_proj', 'avg_loss': '0.00005', 'damp_percent': '0.00500', 'time': '6.314'}\n",
            "INFO - {'layer': 1, 'module': 'self_attn.k_proj', 'avg_loss': '0.00238', 'damp_percent': '0.00500', 'time': '1.603'}\n",
            "INFO - {'layer': 1, 'module': 'self_attn.v_proj', 'avg_loss': '0.00019', 'damp_percent': '0.00500', 'time': '1.615'}\n",
            "INFO - {'layer': 1, 'module': 'self_attn.q_proj', 'avg_loss': '0.00471', 'damp_percent': '0.00500', 'time': '1.652'}\n",
            "INFO - {'layer': 1, 'module': 'self_attn.o_proj', 'avg_loss': '0.00001', 'damp_percent': '0.00500', 'time': '1.695'}\n",
            "INFO - {'layer': 1, 'module': 'mlp.up_proj', 'avg_loss': '0.00831', 'damp_percent': '0.00500', 'time': '1.646'}\n",
            "INFO - {'layer': 1, 'module': 'mlp.gate_proj', 'avg_loss': '0.00979', 'damp_percent': '0.00500', 'time': '1.669'}\n",
            "INFO - {'layer': 1, 'module': 'mlp.down_proj', 'avg_loss': '0.84043', 'damp_percent': '0.00500', 'time': '6.209'}\n",
            "INFO - {'layer': 2, 'module': 'self_attn.k_proj', 'avg_loss': '0.01027', 'damp_percent': '0.00500', 'time': '1.614'}\n",
            "INFO - {'layer': 2, 'module': 'self_attn.v_proj', 'avg_loss': '0.00078', 'damp_percent': '0.00500', 'time': '1.643'}\n",
            "INFO - {'layer': 2, 'module': 'self_attn.q_proj', 'avg_loss': '0.01926', 'damp_percent': '0.00500', 'time': '1.697'}\n",
            "INFO - {'layer': 2, 'module': 'self_attn.o_proj', 'avg_loss': '0.00001', 'damp_percent': '0.00500', 'time': '1.641'}\n",
            "INFO - {'layer': 2, 'module': 'mlp.up_proj', 'avg_loss': '0.01392', 'damp_percent': '0.00500', 'time': '1.650'}\n",
            "INFO - {'layer': 2, 'module': 'mlp.gate_proj', 'avg_loss': '0.01725', 'damp_percent': '0.00500', 'time': '1.678'}\n",
            "INFO - {'layer': 2, 'module': 'mlp.down_proj', 'avg_loss': '0.00002', 'damp_percent': '0.00500', 'time': '6.252'}\n",
            "INFO - {'layer': 3, 'module': 'self_attn.k_proj', 'avg_loss': '0.01386', 'damp_percent': '0.00500', 'time': '1.613'}\n",
            "INFO - {'layer': 3, 'module': 'self_attn.v_proj', 'avg_loss': '0.00147', 'damp_percent': '0.00500', 'time': '1.628'}\n",
            "INFO - {'layer': 3, 'module': 'self_attn.q_proj', 'avg_loss': '0.02667', 'damp_percent': '0.00500', 'time': '1.649'}\n",
            "INFO - {'layer': 3, 'module': 'self_attn.o_proj', 'avg_loss': '0.00002', 'damp_percent': '0.00500', 'time': '1.645'}\n",
            "INFO - {'layer': 3, 'module': 'mlp.up_proj', 'avg_loss': '0.01933', 'damp_percent': '0.00500', 'time': '1.658'}\n",
            "INFO - {'layer': 3, 'module': 'mlp.gate_proj', 'avg_loss': '0.02750', 'damp_percent': '0.00500', 'time': '1.672'}\n",
            "INFO - {'layer': 3, 'module': 'mlp.down_proj', 'avg_loss': '0.00004', 'damp_percent': '0.00500', 'time': '6.234'}\n",
            "INFO - {'layer': 4, 'module': 'self_attn.k_proj', 'avg_loss': '0.01120', 'damp_percent': '0.00500', 'time': '1.604'}\n",
            "INFO - {'layer': 4, 'module': 'self_attn.v_proj', 'avg_loss': '0.00146', 'damp_percent': '0.00500', 'time': '1.640'}\n",
            "INFO - {'layer': 4, 'module': 'self_attn.q_proj', 'avg_loss': '0.02152', 'damp_percent': '0.00500', 'time': '1.658'}\n",
            "INFO - {'layer': 4, 'module': 'self_attn.o_proj', 'avg_loss': '0.00003', 'damp_percent': '0.00500', 'time': '1.617'}\n",
            "INFO - {'layer': 4, 'module': 'mlp.up_proj', 'avg_loss': '0.02430', 'damp_percent': '0.00500', 'time': '1.647'}\n",
            "INFO - {'layer': 4, 'module': 'mlp.gate_proj', 'avg_loss': '0.03881', 'damp_percent': '0.00500', 'time': '1.668'}\n",
            "INFO - {'layer': 4, 'module': 'mlp.down_proj', 'avg_loss': '0.00007', 'damp_percent': '0.00500', 'time': '6.310'}\n",
            "INFO - {'layer': 5, 'module': 'self_attn.k_proj', 'avg_loss': '0.01470', 'damp_percent': '0.00500', 'time': '1.606'}\n",
            "INFO - {'layer': 5, 'module': 'self_attn.v_proj', 'avg_loss': '0.00134', 'damp_percent': '0.00500', 'time': '1.625'}\n",
            "INFO - {'layer': 5, 'module': 'self_attn.q_proj', 'avg_loss': '0.02803', 'damp_percent': '0.00500', 'time': '1.647'}\n",
            "INFO - {'layer': 5, 'module': 'self_attn.o_proj', 'avg_loss': '0.00003', 'damp_percent': '0.00500', 'time': '1.621'}\n",
            "INFO - {'layer': 5, 'module': 'mlp.up_proj', 'avg_loss': '0.02872', 'damp_percent': '0.00500', 'time': '1.651'}\n",
            "INFO - {'layer': 5, 'module': 'mlp.gate_proj', 'avg_loss': '0.04535', 'damp_percent': '0.00500', 'time': '1.660'}\n",
            "INFO - {'layer': 5, 'module': 'mlp.down_proj', 'avg_loss': '0.00010', 'damp_percent': '0.00500', 'time': '6.214'}\n",
            "INFO - {'layer': 6, 'module': 'self_attn.k_proj', 'avg_loss': '0.01468', 'damp_percent': '0.00500', 'time': '1.601'}\n",
            "INFO - {'layer': 6, 'module': 'self_attn.v_proj', 'avg_loss': '0.00162', 'damp_percent': '0.00500', 'time': '1.629'}\n",
            "INFO - {'layer': 6, 'module': 'self_attn.q_proj', 'avg_loss': '0.02949', 'damp_percent': '0.00500', 'time': '1.647'}\n",
            "INFO - {'layer': 6, 'module': 'self_attn.o_proj', 'avg_loss': '0.00006', 'damp_percent': '0.00500', 'time': '1.634'}\n",
            "INFO - {'layer': 6, 'module': 'mlp.up_proj', 'avg_loss': '0.03058', 'damp_percent': '0.00500', 'time': '1.655'}\n",
            "INFO - {'layer': 6, 'module': 'mlp.gate_proj', 'avg_loss': '0.04875', 'damp_percent': '0.00500', 'time': '1.663'}\n",
            "INFO - {'layer': 6, 'module': 'mlp.down_proj', 'avg_loss': '0.00013', 'damp_percent': '0.00500', 'time': '6.217'}\n",
            "INFO - {'layer': 7, 'module': 'self_attn.k_proj', 'avg_loss': '0.01619', 'damp_percent': '0.00500', 'time': '1.601'}\n",
            "INFO - {'layer': 7, 'module': 'self_attn.v_proj', 'avg_loss': '0.00164', 'damp_percent': '0.00500', 'time': '1.613'}\n",
            "INFO - {'layer': 7, 'module': 'self_attn.q_proj', 'avg_loss': '0.02940', 'damp_percent': '0.00500', 'time': '1.649'}\n",
            "INFO - {'layer': 7, 'module': 'self_attn.o_proj', 'avg_loss': '0.00010', 'damp_percent': '0.00500', 'time': '1.632'}\n",
            "INFO - {'layer': 7, 'module': 'mlp.up_proj', 'avg_loss': '0.03146', 'damp_percent': '0.00500', 'time': '1.669'}\n",
            "INFO - {'layer': 7, 'module': 'mlp.gate_proj', 'avg_loss': '0.04726', 'damp_percent': '0.00500', 'time': '1.675'}\n",
            "INFO - {'layer': 7, 'module': 'mlp.down_proj', 'avg_loss': '0.00016', 'damp_percent': '0.00500', 'time': '6.232'}\n",
            "INFO - {'layer': 8, 'module': 'self_attn.k_proj', 'avg_loss': '0.01793', 'damp_percent': '0.00500', 'time': '1.607'}\n",
            "INFO - {'layer': 8, 'module': 'self_attn.v_proj', 'avg_loss': '0.00210', 'damp_percent': '0.00500', 'time': '1.622'}\n",
            "INFO - {'layer': 8, 'module': 'self_attn.q_proj', 'avg_loss': '0.03302', 'damp_percent': '0.00500', 'time': '1.676'}\n",
            "INFO - {'layer': 8, 'module': 'self_attn.o_proj', 'avg_loss': '0.00012', 'damp_percent': '0.00500', 'time': '1.622'}\n",
            "INFO - {'layer': 8, 'module': 'mlp.up_proj', 'avg_loss': '0.03190', 'damp_percent': '0.00500', 'time': '1.643'}\n",
            "INFO - {'layer': 8, 'module': 'mlp.gate_proj', 'avg_loss': '0.04822', 'damp_percent': '0.00500', 'time': '1.664'}\n",
            "INFO - {'layer': 8, 'module': 'mlp.down_proj', 'avg_loss': '0.00015', 'damp_percent': '0.00500', 'time': '6.257'}\n",
            "INFO - {'layer': 9, 'module': 'self_attn.k_proj', 'avg_loss': '0.01798', 'damp_percent': '0.00500', 'time': '1.608'}\n",
            "INFO - {'layer': 9, 'module': 'self_attn.v_proj', 'avg_loss': '0.00277', 'damp_percent': '0.00500', 'time': '1.603'}\n",
            "INFO - {'layer': 9, 'module': 'self_attn.q_proj', 'avg_loss': '0.03262', 'damp_percent': '0.00500', 'time': '1.657'}\n",
            "INFO - {'layer': 9, 'module': 'self_attn.o_proj', 'avg_loss': '0.00014', 'damp_percent': '0.00500', 'time': '1.647'}\n",
            "INFO - {'layer': 9, 'module': 'mlp.up_proj', 'avg_loss': '0.03147', 'damp_percent': '0.00500', 'time': '1.667'}\n",
            "INFO - {'layer': 9, 'module': 'mlp.gate_proj', 'avg_loss': '0.04817', 'damp_percent': '0.00500', 'time': '1.678'}\n",
            "INFO - {'layer': 9, 'module': 'mlp.down_proj', 'avg_loss': '0.00015', 'damp_percent': '0.00500', 'time': '6.253'}\n",
            "INFO - {'layer': 10, 'module': 'self_attn.k_proj', 'avg_loss': '0.01924', 'damp_percent': '0.00500', 'time': '1.620'}\n",
            "INFO - {'layer': 10, 'module': 'self_attn.v_proj', 'avg_loss': '0.00217', 'damp_percent': '0.00500', 'time': '1.624'}\n",
            "INFO - {'layer': 10, 'module': 'self_attn.q_proj', 'avg_loss': '0.03551', 'damp_percent': '0.00500', 'time': '1.660'}\n",
            "INFO - {'layer': 10, 'module': 'self_attn.o_proj', 'avg_loss': '0.00012', 'damp_percent': '0.00500', 'time': '1.624'}\n",
            "INFO - {'layer': 10, 'module': 'mlp.up_proj', 'avg_loss': '0.03116', 'damp_percent': '0.00500', 'time': '1.651'}\n",
            "INFO - {'layer': 10, 'module': 'mlp.gate_proj', 'avg_loss': '0.04442', 'damp_percent': '0.00500', 'time': '1.675'}\n",
            "INFO - {'layer': 10, 'module': 'mlp.down_proj', 'avg_loss': '0.00017', 'damp_percent': '0.00500', 'time': '6.284'}\n",
            "INFO - {'layer': 11, 'module': 'self_attn.k_proj', 'avg_loss': '0.01967', 'damp_percent': '0.00500', 'time': '1.605'}\n",
            "INFO - {'layer': 11, 'module': 'self_attn.v_proj', 'avg_loss': '0.00211', 'damp_percent': '0.00500', 'time': '1.615'}\n",
            "INFO - {'layer': 11, 'module': 'self_attn.q_proj', 'avg_loss': '0.03333', 'damp_percent': '0.00500', 'time': '1.648'}\n",
            "INFO - {'layer': 11, 'module': 'self_attn.o_proj', 'avg_loss': '0.00015', 'damp_percent': '0.00500', 'time': '1.649'}\n",
            "INFO - {'layer': 11, 'module': 'mlp.up_proj', 'avg_loss': '0.03168', 'damp_percent': '0.00500', 'time': '1.662'}\n",
            "INFO - {'layer': 11, 'module': 'mlp.gate_proj', 'avg_loss': '0.04335', 'damp_percent': '0.00500', 'time': '1.662'}\n",
            "INFO - {'layer': 11, 'module': 'mlp.down_proj', 'avg_loss': '0.00016', 'damp_percent': '0.00500', 'time': '6.254'}\n",
            "INFO - {'layer': 12, 'module': 'self_attn.k_proj', 'avg_loss': '0.01659', 'damp_percent': '0.00500', 'time': '1.610'}\n",
            "INFO - {'layer': 12, 'module': 'self_attn.v_proj', 'avg_loss': '0.00256', 'damp_percent': '0.00500', 'time': '1.615'}\n",
            "INFO - {'layer': 12, 'module': 'self_attn.q_proj', 'avg_loss': '0.03003', 'damp_percent': '0.00500', 'time': '1.650'}\n",
            "INFO - {'layer': 12, 'module': 'self_attn.o_proj', 'avg_loss': '0.00018', 'damp_percent': '0.00500', 'time': '1.646'}\n",
            "INFO - {'layer': 12, 'module': 'mlp.up_proj', 'avg_loss': '0.03084', 'damp_percent': '0.00500', 'time': '1.686'}\n",
            "INFO - {'layer': 12, 'module': 'mlp.gate_proj', 'avg_loss': '0.03949', 'damp_percent': '0.00500', 'time': '1.674'}\n",
            "INFO - {'layer': 12, 'module': 'mlp.down_proj', 'avg_loss': '0.00017', 'damp_percent': '0.00500', 'time': '6.289'}\n",
            "INFO - {'layer': 13, 'module': 'self_attn.k_proj', 'avg_loss': '0.02102', 'damp_percent': '0.00500', 'time': '1.626'}\n",
            "INFO - {'layer': 13, 'module': 'self_attn.v_proj', 'avg_loss': '0.00273', 'damp_percent': '0.00500', 'time': '1.644'}\n",
            "INFO - {'layer': 13, 'module': 'self_attn.q_proj', 'avg_loss': '0.03727', 'damp_percent': '0.00500', 'time': '1.675'}\n",
            "INFO - {'layer': 13, 'module': 'self_attn.o_proj', 'avg_loss': '0.00015', 'damp_percent': '0.00500', 'time': '1.643'}\n",
            "INFO - {'layer': 13, 'module': 'mlp.up_proj', 'avg_loss': '0.03224', 'damp_percent': '0.00500', 'time': '1.673'}\n",
            "INFO - {'layer': 13, 'module': 'mlp.gate_proj', 'avg_loss': '0.04095', 'damp_percent': '0.00500', 'time': '1.690'}\n",
            "INFO - {'layer': 13, 'module': 'mlp.down_proj', 'avg_loss': '0.00019', 'damp_percent': '0.00500', 'time': '6.347'}\n",
            "INFO - {'layer': 14, 'module': 'self_attn.k_proj', 'avg_loss': '0.02097', 'damp_percent': '0.00500', 'time': '1.633'}\n",
            "INFO - {'layer': 14, 'module': 'self_attn.v_proj', 'avg_loss': '0.00269', 'damp_percent': '0.00500', 'time': '1.623'}\n",
            "INFO - {'layer': 14, 'module': 'self_attn.q_proj', 'avg_loss': '0.03636', 'damp_percent': '0.00500', 'time': '1.670'}\n",
            "INFO - {'layer': 14, 'module': 'self_attn.o_proj', 'avg_loss': '0.00018', 'damp_percent': '0.00500', 'time': '1.644'}\n",
            "INFO - {'layer': 14, 'module': 'mlp.up_proj', 'avg_loss': '0.03487', 'damp_percent': '0.00500', 'time': '1.653'}\n",
            "INFO - {'layer': 14, 'module': 'mlp.gate_proj', 'avg_loss': '0.04589', 'damp_percent': '0.00500', 'time': '1.701'}\n",
            "INFO - {'layer': 14, 'module': 'mlp.down_proj', 'avg_loss': '0.00024', 'damp_percent': '0.00500', 'time': '6.262'}\n",
            "INFO - {'layer': 15, 'module': 'self_attn.k_proj', 'avg_loss': '0.02006', 'damp_percent': '0.00500', 'time': '1.601'}\n",
            "INFO - {'layer': 15, 'module': 'self_attn.v_proj', 'avg_loss': '0.00311', 'damp_percent': '0.00500', 'time': '1.697'}\n",
            "INFO - {'layer': 15, 'module': 'self_attn.q_proj', 'avg_loss': '0.04323', 'damp_percent': '0.00500', 'time': '1.673'}\n",
            "INFO - {'layer': 15, 'module': 'self_attn.o_proj', 'avg_loss': '0.00018', 'damp_percent': '0.00500', 'time': '1.634'}\n",
            "INFO - {'layer': 15, 'module': 'mlp.up_proj', 'avg_loss': '0.03869', 'damp_percent': '0.00500', 'time': '1.662'}\n",
            "INFO - {'layer': 15, 'module': 'mlp.gate_proj', 'avg_loss': '0.05388', 'damp_percent': '0.00500', 'time': '1.667'}\n",
            "INFO - {'layer': 15, 'module': 'mlp.down_proj', 'avg_loss': '0.00030', 'damp_percent': '0.00500', 'time': '6.266'}\n",
            "INFO - {'layer': 16, 'module': 'self_attn.k_proj', 'avg_loss': '0.02000', 'damp_percent': '0.00500', 'time': '1.615'}\n",
            "INFO - {'layer': 16, 'module': 'self_attn.v_proj', 'avg_loss': '0.00263', 'damp_percent': '0.00500', 'time': '1.623'}\n",
            "INFO - {'layer': 16, 'module': 'self_attn.q_proj', 'avg_loss': '0.03986', 'damp_percent': '0.00500', 'time': '1.666'}\n",
            "INFO - {'layer': 16, 'module': 'self_attn.o_proj', 'avg_loss': '0.00018', 'damp_percent': '0.00500', 'time': '1.630'}\n",
            "INFO - {'layer': 16, 'module': 'mlp.up_proj', 'avg_loss': '0.04260', 'damp_percent': '0.00500', 'time': '1.683'}\n",
            "INFO - {'layer': 16, 'module': 'mlp.gate_proj', 'avg_loss': '0.06429', 'damp_percent': '0.00500', 'time': '1.694'}\n",
            "INFO - {'layer': 16, 'module': 'mlp.down_proj', 'avg_loss': '0.00035', 'damp_percent': '0.00500', 'time': '6.264'}\n",
            "INFO - {'layer': 17, 'module': 'self_attn.k_proj', 'avg_loss': '0.02126', 'damp_percent': '0.00500', 'time': '1.604'}\n",
            "INFO - {'layer': 17, 'module': 'self_attn.v_proj', 'avg_loss': '0.00350', 'damp_percent': '0.00500', 'time': '1.638'}\n",
            "INFO - {'layer': 17, 'module': 'self_attn.q_proj', 'avg_loss': '0.04381', 'damp_percent': '0.00500', 'time': '1.663'}\n",
            "INFO - {'layer': 17, 'module': 'self_attn.o_proj', 'avg_loss': '0.00012', 'damp_percent': '0.00500', 'time': '1.638'}\n",
            "INFO - {'layer': 17, 'module': 'mlp.up_proj', 'avg_loss': '0.04671', 'damp_percent': '0.00500', 'time': '1.655'}\n",
            "INFO - {'layer': 17, 'module': 'mlp.gate_proj', 'avg_loss': '0.07192', 'damp_percent': '0.00500', 'time': '1.666'}\n",
            "INFO - {'layer': 17, 'module': 'mlp.down_proj', 'avg_loss': '0.00042', 'damp_percent': '0.00500', 'time': '6.274'}\n",
            "INFO - {'layer': 18, 'module': 'self_attn.k_proj', 'avg_loss': '0.02425', 'damp_percent': '0.00500', 'time': '1.604'}\n",
            "INFO - {'layer': 18, 'module': 'self_attn.v_proj', 'avg_loss': '0.00311', 'damp_percent': '0.00500', 'time': '1.616'}\n",
            "INFO - {'layer': 18, 'module': 'self_attn.q_proj', 'avg_loss': '0.04720', 'damp_percent': '0.00500', 'time': '1.656'}\n",
            "INFO - {'layer': 18, 'module': 'self_attn.o_proj', 'avg_loss': '0.00009', 'damp_percent': '0.00500', 'time': '1.627'}\n",
            "INFO - {'layer': 18, 'module': 'mlp.up_proj', 'avg_loss': '0.05035', 'damp_percent': '0.00500', 'time': '1.667'}\n",
            "INFO - {'layer': 18, 'module': 'mlp.gate_proj', 'avg_loss': '0.07981', 'damp_percent': '0.00500', 'time': '1.741'}\n",
            "INFO - {'layer': 18, 'module': 'mlp.down_proj', 'avg_loss': '0.00044', 'damp_percent': '0.00500', 'time': '6.248'}\n",
            "INFO - {'layer': 19, 'module': 'self_attn.k_proj', 'avg_loss': '0.02354', 'damp_percent': '0.00500', 'time': '1.620'}\n",
            "INFO - {'layer': 19, 'module': 'self_attn.v_proj', 'avg_loss': '0.00364', 'damp_percent': '0.00500', 'time': '1.623'}\n",
            "INFO - {'layer': 19, 'module': 'self_attn.q_proj', 'avg_loss': '0.04848', 'damp_percent': '0.00500', 'time': '1.647'}\n",
            "INFO - {'layer': 19, 'module': 'self_attn.o_proj', 'avg_loss': '0.00007', 'damp_percent': '0.00500', 'time': '1.640'}\n",
            "INFO - {'layer': 19, 'module': 'mlp.up_proj', 'avg_loss': '0.05403', 'damp_percent': '0.00500', 'time': '1.648'}\n",
            "INFO - {'layer': 19, 'module': 'mlp.gate_proj', 'avg_loss': '0.08745', 'damp_percent': '0.00500', 'time': '1.663'}\n",
            "INFO - {'layer': 19, 'module': 'mlp.down_proj', 'avg_loss': '0.00048', 'damp_percent': '0.00500', 'time': '6.256'}\n",
            "INFO - {'layer': 20, 'module': 'self_attn.k_proj', 'avg_loss': '0.02356', 'damp_percent': '0.00500', 'time': '1.597'}\n",
            "INFO - {'layer': 20, 'module': 'self_attn.v_proj', 'avg_loss': '0.00422', 'damp_percent': '0.00500', 'time': '1.600'}\n",
            "INFO - {'layer': 20, 'module': 'self_attn.q_proj', 'avg_loss': '0.04948', 'damp_percent': '0.00500', 'time': '1.629'}\n",
            "INFO - {'layer': 20, 'module': 'self_attn.o_proj', 'avg_loss': '0.00009', 'damp_percent': '0.00500', 'time': '1.624'}\n",
            "INFO - {'layer': 20, 'module': 'mlp.up_proj', 'avg_loss': '0.05972', 'damp_percent': '0.00500', 'time': '1.661'}\n",
            "INFO - {'layer': 20, 'module': 'mlp.gate_proj', 'avg_loss': '0.09566', 'damp_percent': '0.00500', 'time': '1.681'}\n",
            "INFO - {'layer': 20, 'module': 'mlp.down_proj', 'avg_loss': '0.00052', 'damp_percent': '0.00500', 'time': '6.237'}\n",
            "INFO - {'layer': 21, 'module': 'self_attn.k_proj', 'avg_loss': '0.02444', 'damp_percent': '0.00500', 'time': '1.627'}\n",
            "INFO - {'layer': 21, 'module': 'self_attn.v_proj', 'avg_loss': '0.00458', 'damp_percent': '0.00500', 'time': '1.623'}\n",
            "INFO - {'layer': 21, 'module': 'self_attn.q_proj', 'avg_loss': '0.04822', 'damp_percent': '0.00500', 'time': '1.659'}\n",
            "INFO - {'layer': 21, 'module': 'self_attn.o_proj', 'avg_loss': '0.00013', 'damp_percent': '0.00500', 'time': '1.629'}\n",
            "INFO - {'layer': 21, 'module': 'mlp.up_proj', 'avg_loss': '0.06599', 'damp_percent': '0.00500', 'time': '1.650'}\n",
            "INFO - {'layer': 21, 'module': 'mlp.gate_proj', 'avg_loss': '0.10653', 'damp_percent': '0.00500', 'time': '1.670'}\n",
            "INFO - {'layer': 21, 'module': 'mlp.down_proj', 'avg_loss': '0.00060', 'damp_percent': '0.00500', 'time': '6.253'}\n",
            "INFO - {'layer': 22, 'module': 'self_attn.k_proj', 'avg_loss': '0.02509', 'damp_percent': '0.00500', 'time': '1.609'}\n",
            "INFO - {'layer': 22, 'module': 'self_attn.v_proj', 'avg_loss': '0.00537', 'damp_percent': '0.00500', 'time': '1.616'}\n",
            "INFO - {'layer': 22, 'module': 'self_attn.q_proj', 'avg_loss': '0.04935', 'damp_percent': '0.00500', 'time': '1.651'}\n",
            "INFO - {'layer': 22, 'module': 'self_attn.o_proj', 'avg_loss': '0.00008', 'damp_percent': '0.00500', 'time': '1.643'}\n",
            "INFO - {'layer': 22, 'module': 'mlp.up_proj', 'avg_loss': '0.07020', 'damp_percent': '0.00500', 'time': '1.666'}\n",
            "INFO - {'layer': 22, 'module': 'mlp.gate_proj', 'avg_loss': '0.11305', 'damp_percent': '0.00500', 'time': '1.673'}\n",
            "INFO - {'layer': 22, 'module': 'mlp.down_proj', 'avg_loss': '0.00063', 'damp_percent': '0.00500', 'time': '6.245'}\n",
            "INFO - {'layer': 23, 'module': 'self_attn.k_proj', 'avg_loss': '0.02611', 'damp_percent': '0.00500', 'time': '1.621'}\n",
            "INFO - {'layer': 23, 'module': 'self_attn.v_proj', 'avg_loss': '0.00631', 'damp_percent': '0.00500', 'time': '1.641'}\n",
            "INFO - {'layer': 23, 'module': 'self_attn.q_proj', 'avg_loss': '0.05167', 'damp_percent': '0.00500', 'time': '1.654'}\n",
            "INFO - {'layer': 23, 'module': 'self_attn.o_proj', 'avg_loss': '0.00010', 'damp_percent': '0.00500', 'time': '1.628'}\n",
            "INFO - {'layer': 23, 'module': 'mlp.up_proj', 'avg_loss': '0.07539', 'damp_percent': '0.00500', 'time': '1.647'}\n",
            "INFO - {'layer': 23, 'module': 'mlp.gate_proj', 'avg_loss': '0.12104', 'damp_percent': '0.00500', 'time': '1.667'}\n",
            "INFO - {'layer': 23, 'module': 'mlp.down_proj', 'avg_loss': '0.00067', 'damp_percent': '0.00500', 'time': '6.251'}\n",
            "INFO - {'layer': 24, 'module': 'self_attn.k_proj', 'avg_loss': '0.02364', 'damp_percent': '0.00500', 'time': '1.606'}\n",
            "INFO - {'layer': 24, 'module': 'self_attn.v_proj', 'avg_loss': '0.00752', 'damp_percent': '0.00500', 'time': '1.611'}\n",
            "INFO - {'layer': 24, 'module': 'self_attn.q_proj', 'avg_loss': '0.04962', 'damp_percent': '0.00500', 'time': '1.652'}\n",
            "INFO - {'layer': 24, 'module': 'self_attn.o_proj', 'avg_loss': '0.00011', 'damp_percent': '0.00500', 'time': '1.634'}\n",
            "INFO - {'layer': 24, 'module': 'mlp.up_proj', 'avg_loss': '0.08004', 'damp_percent': '0.00500', 'time': '1.665'}\n",
            "INFO - {'layer': 24, 'module': 'mlp.gate_proj', 'avg_loss': '0.12830', 'damp_percent': '0.00500', 'time': '1.664'}\n",
            "INFO - {'layer': 24, 'module': 'mlp.down_proj', 'avg_loss': '0.00070', 'damp_percent': '0.00500', 'time': '6.254'}\n",
            "INFO - {'layer': 25, 'module': 'self_attn.k_proj', 'avg_loss': '0.02458', 'damp_percent': '0.00500', 'time': '1.611'}\n",
            "INFO - {'layer': 25, 'module': 'self_attn.v_proj', 'avg_loss': '0.00779', 'damp_percent': '0.00500', 'time': '1.623'}\n",
            "INFO - {'layer': 25, 'module': 'self_attn.q_proj', 'avg_loss': '0.04974', 'damp_percent': '0.00500', 'time': '1.651'}\n",
            "INFO - {'layer': 25, 'module': 'self_attn.o_proj', 'avg_loss': '0.00016', 'damp_percent': '0.00500', 'time': '1.626'}\n",
            "INFO - {'layer': 25, 'module': 'mlp.up_proj', 'avg_loss': '0.08645', 'damp_percent': '0.00500', 'time': '1.692'}\n",
            "INFO - {'layer': 25, 'module': 'mlp.gate_proj', 'avg_loss': '0.13866', 'damp_percent': '0.00500', 'time': '1.683'}\n",
            "INFO - {'layer': 25, 'module': 'mlp.down_proj', 'avg_loss': '0.00080', 'damp_percent': '0.00500', 'time': '6.230'}\n",
            "INFO - {'layer': 26, 'module': 'self_attn.k_proj', 'avg_loss': '0.02344', 'damp_percent': '0.00500', 'time': '1.605'}\n",
            "INFO - {'layer': 26, 'module': 'self_attn.v_proj', 'avg_loss': '0.00817', 'damp_percent': '0.00500', 'time': '1.620'}\n",
            "INFO - {'layer': 26, 'module': 'self_attn.q_proj', 'avg_loss': '0.04547', 'damp_percent': '0.00500', 'time': '1.670'}\n",
            "INFO - {'layer': 26, 'module': 'self_attn.o_proj', 'avg_loss': '0.00017', 'damp_percent': '0.00500', 'time': '1.628'}\n",
            "INFO - {'layer': 26, 'module': 'mlp.up_proj', 'avg_loss': '0.09256', 'damp_percent': '0.00500', 'time': '1.652'}\n",
            "INFO - {'layer': 26, 'module': 'mlp.gate_proj', 'avg_loss': '0.14886', 'damp_percent': '0.00500', 'time': '1.675'}\n",
            "INFO - {'layer': 26, 'module': 'mlp.down_proj', 'avg_loss': '0.00091', 'damp_percent': '0.00500', 'time': '6.236'}\n",
            "INFO - {'layer': 27, 'module': 'self_attn.k_proj', 'avg_loss': '0.02482', 'damp_percent': '0.00500', 'time': '1.612'}\n",
            "INFO - {'layer': 27, 'module': 'self_attn.v_proj', 'avg_loss': '0.00965', 'damp_percent': '0.00500', 'time': '1.626'}\n",
            "INFO - {'layer': 27, 'module': 'self_attn.q_proj', 'avg_loss': '0.04852', 'damp_percent': '0.00500', 'time': '1.663'}\n",
            "INFO - {'layer': 27, 'module': 'self_attn.o_proj', 'avg_loss': '0.00026', 'damp_percent': '0.00500', 'time': '1.634'}\n",
            "INFO - {'layer': 27, 'module': 'mlp.up_proj', 'avg_loss': '0.10096', 'damp_percent': '0.00500', 'time': '1.657'}\n",
            "INFO - {'layer': 27, 'module': 'mlp.gate_proj', 'avg_loss': '0.16123', 'damp_percent': '0.00500', 'time': '1.674'}\n",
            "INFO - {'layer': 27, 'module': 'mlp.down_proj', 'avg_loss': '0.00115', 'damp_percent': '0.00500', 'time': '6.241'}\n",
            "INFO - {'layer': 28, 'module': 'self_attn.k_proj', 'avg_loss': '0.02206', 'damp_percent': '0.00500', 'time': '1.614'}\n",
            "INFO - {'layer': 28, 'module': 'self_attn.v_proj', 'avg_loss': '0.01089', 'damp_percent': '0.00500', 'time': '1.626'}\n",
            "INFO - {'layer': 28, 'module': 'self_attn.q_proj', 'avg_loss': '0.04739', 'damp_percent': '0.00500', 'time': '1.670'}\n",
            "INFO - {'layer': 28, 'module': 'self_attn.o_proj', 'avg_loss': '0.00039', 'damp_percent': '0.00500', 'time': '1.620'}\n",
            "INFO - {'layer': 28, 'module': 'mlp.up_proj', 'avg_loss': '0.11278', 'damp_percent': '0.00500', 'time': '1.651'}\n",
            "INFO - {'layer': 28, 'module': 'mlp.gate_proj', 'avg_loss': '0.17125', 'damp_percent': '0.00500', 'time': '1.659'}\n",
            "INFO - {'layer': 28, 'module': 'mlp.down_proj', 'avg_loss': '0.00154', 'damp_percent': '0.00500', 'time': '6.211'}\n",
            "INFO - {'layer': 29, 'module': 'self_attn.k_proj', 'avg_loss': '0.02733', 'damp_percent': '0.00500', 'time': '1.606'}\n",
            "INFO - {'layer': 29, 'module': 'self_attn.v_proj', 'avg_loss': '0.01282', 'damp_percent': '0.00500', 'time': '1.613'}\n",
            "INFO - {'layer': 29, 'module': 'self_attn.q_proj', 'avg_loss': '0.05175', 'damp_percent': '0.00500', 'time': '1.648'}\n",
            "INFO - {'layer': 29, 'module': 'self_attn.o_proj', 'avg_loss': '0.00057', 'damp_percent': '0.00500', 'time': '1.618'}\n",
            "INFO - {'layer': 29, 'module': 'mlp.up_proj', 'avg_loss': '0.12045', 'damp_percent': '0.00500', 'time': '1.652'}\n",
            "INFO - {'layer': 29, 'module': 'mlp.gate_proj', 'avg_loss': '0.17405', 'damp_percent': '0.00500', 'time': '1.664'}\n",
            "INFO - {'layer': 29, 'module': 'mlp.down_proj', 'avg_loss': '0.00224', 'damp_percent': '0.00500', 'time': '6.246'}\n",
            "INFO - {'layer': 30, 'module': 'self_attn.k_proj', 'avg_loss': '0.01650', 'damp_percent': '0.00500', 'time': '1.611'}\n",
            "INFO - {'layer': 30, 'module': 'self_attn.v_proj', 'avg_loss': '0.01472', 'damp_percent': '0.00500', 'time': '1.650'}\n",
            "INFO - {'layer': 30, 'module': 'self_attn.q_proj', 'avg_loss': '0.03854', 'damp_percent': '0.00500', 'time': '1.658'}\n",
            "INFO - {'layer': 30, 'module': 'self_attn.o_proj', 'avg_loss': '0.00076', 'damp_percent': '0.00500', 'time': '1.627'}\n",
            "INFO - {'layer': 30, 'module': 'mlp.up_proj', 'avg_loss': '0.12522', 'damp_percent': '0.00500', 'time': '1.671'}\n",
            "INFO - {'layer': 30, 'module': 'mlp.gate_proj', 'avg_loss': '0.18604', 'damp_percent': '0.00500', 'time': '1.667'}\n",
            "INFO - {'layer': 30, 'module': 'mlp.down_proj', 'avg_loss': '0.00419', 'damp_percent': '0.00500', 'time': '6.293'}\n",
            "INFO - {'layer': 31, 'module': 'self_attn.k_proj', 'avg_loss': '0.01680', 'damp_percent': '0.00500', 'time': '1.608'}\n",
            "INFO - {'layer': 31, 'module': 'self_attn.v_proj', 'avg_loss': '0.00901', 'damp_percent': '0.00500', 'time': '1.614'}\n",
            "INFO - {'layer': 31, 'module': 'self_attn.q_proj', 'avg_loss': '0.03791', 'damp_percent': '0.00500', 'time': '1.646'}\n",
            "INFO - {'layer': 31, 'module': 'self_attn.o_proj', 'avg_loss': '0.00333', 'damp_percent': '0.00500', 'time': '1.627'}\n",
            "INFO - {'layer': 31, 'module': 'mlp.up_proj', 'avg_loss': '0.11848', 'damp_percent': '0.00500', 'time': '1.680'}\n",
            "INFO - {'layer': 31, 'module': 'mlp.gate_proj', 'avg_loss': '0.17089', 'damp_percent': '0.00500', 'time': '1.672'}\n",
            "INFO - {'layer': 31, 'module': 'mlp.down_proj', 'avg_loss': '0.06427', 'damp_percent': '0.00500', 'time': '6.230'}\n",
            "INFO - Packing model...\n",
            "INFO:gptqmodel.utils.model:Packing model...\n",
            "Packing model.layers.31.mlp.down_proj: 100%|██████████| 224/224 [03:39<00:00,  1.02it/s]\n",
            "INFO - Model packed.\n",
            "INFO:gptqmodel.utils.model:Model packed.\n",
            "INFO - Pre-Quantized model size: 30633.14MB, 29.92GB\n",
            "INFO - Quantized model size: 5467.36MB, 5.34GB\n",
            "INFO - Size difference: 25165.78MB, 24.58GB - 82.15%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model is quantized and saved at \"Meta-Llama-3.1-8B-Instruct-4bit\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPTQModel.from_quantized(quantized_model_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y551VI6OSgvZ",
        "outputId": "5a764783-992e-47b5-b894-3514f9179ceb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO - Compatibility: converting `checkpoint_format` from `gptq` to `gptq_v2`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.decode(model.generate(**tokenizer(\"gptqmodel is\", return_tensors=\"pt\").to(model.device))[0]))"
      ],
      "metadata": {
        "id": "WLhtWVPdSm2e",
        "outputId": "544ab006-2e90-406a-de3e-5e7501e2dab7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1220: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n",
            "Starting from v4.46, the `logits` model output will have the same type as the model (except at train time, where it will always be FP32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<|begin_of_text|>gptqmodel is a Python package for working with the GPT-Q model. It provides\n"
          ]
        }
      ]
    }
  ]
}